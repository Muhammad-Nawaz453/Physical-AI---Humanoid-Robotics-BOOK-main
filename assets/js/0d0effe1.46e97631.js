"use strict";(globalThis.webpackChunkmy_book=globalThis.webpackChunkmy_book||[]).push([[3184],{4026:(e,r,n)=>{n.r(r),n.d(r,{assets:()=>c,contentTitle:()=>l,default:()=>_,frontMatter:()=>i,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"module-1/project-ros2-package","title":"Complete ROS 2 Package Project - Building Your First Robot Application","description":"<ChapterControls","source":"@site/docs/module-1/project-ros2-package.mdx","sourceDirName":"module-1","slug":"/module-1/project-ros2-package","permalink":"/https://github.com/Muhammad-Nawaz453/Physical-AI---Humanoid-Robotics-BOOK/module-1/project-ros2-package","draft":false,"unlisted":false,"editUrl":"https://github.com/Muhammad-Nawaz453/Physical-AI---Humanoid-Robotics/tree/main/docs/module-1/project-ros2-package.mdx","tags":[],"version":"current","frontMatter":{"title":"Complete ROS 2 Package Project - Building Your First Robot Application"},"sidebar":"tutorialSidebar","previous":{"title":"\ud83d\ude80 Launch Files - Orchestrating Your ROS 2 System","permalink":"/https://github.com/Muhammad-Nawaz453/Physical-AI---Humanoid-Robotics-BOOK/module-1/launch-files"},"next":{"title":"\ud83c\udf10 Introduction to Simulation and Digital Twins","permalink":"/https://github.com/Muhammad-Nawaz453/Physical-AI---Humanoid-Robotics-BOOK/module-2/introduction"}}');var a=n(4848),s=n(8453),o=n(7197);const i={title:"Complete ROS 2 Package Project - Building Your First Robot Application"},l=void 0,c={},d=[{value:"sidebar_position: 8",id:"sidebar_position-8",level:2},{value:"\ud83c\udfaf Learning Objectives",id:"-learning-objectives",level:2},{value:"\ud83c\udfd7\ufe0f Project Overview: Autonomous Delivery Robot",id:"\ufe0f-project-overview-autonomous-delivery-robot",level:2},{value:"Package Structure",id:"package-structure",level:3},{value:"\ud83d\udd27 Creating the Package Files",id:"-creating-the-package-files",level:2},{value:"1. Package Manifest (package.xml)",id:"1-package-manifest-packagexml",level:3},{value:"2. Setup Configuration (setup.py)",id:"2-setup-configuration-setuppy",level:3},{value:"3. Robot Description (URDF/Xacro)",id:"3-robot-description-urdfxacro",level:3},{value:"4. Main Robot Controller Node",id:"4-main-robot-controller-node",level:3},{value:"5. Sensor Processing Node",id:"5-sensor-processing-node",level:3},{value:"6. Delivery State Machine Node",id:"6-delivery-state-machine-node",level:3},{value:"7. Launch File for the Complete System",id:"7-launch-file-for-the-complete-system",level:3},{value:"8. Configuration Files",id:"8-configuration-files",level:3},{value:"9. RViz Configuration",id:"9-rviz-configuration",level:3},{value:"\ud83e\uddea Hands-On Exercise: Complete the Delivery Robot System",id:"-hands-on-exercise-complete-the-delivery-robot-system",level:2},{value:"\ud83d\udca1 Key Takeaways",id:"-key-takeaways",level:2},{value:"\ud83d\udcda Further Reading",id:"-further-reading",level:2}];function m(e){const r={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(o.A,{chapterContent:"\n  # Your chapter content here\n  \n  This is the text that will be personalized and translated.\n",userBackground:"undefined"!=typeof window?JSON.parse(localStorage.getItem("user")||"{}"):{}}),"\n",(0,a.jsx)(r.hr,{}),"\n",(0,a.jsx)(r.h2,{id:"sidebar_position-8",children:"sidebar_position: 8"}),"\n",(0,a.jsx)(r.h1,{id:"\ufe0f-complete-ros-2-package-project---building-your-first-robot-application",children:"\ud83c\udfd7\ufe0f Complete ROS 2 Package Project - Building Your First Robot Application"}),"\n",(0,a.jsx)(r.p,{children:"In this comprehensive project, you'll build a complete ROS 2 package that integrates all the concepts learned in Module 1. You'll create a mobile robot application that includes nodes for sensor processing, navigation, and control, all orchestrated with launch files and described with URDF."}),"\n",(0,a.jsx)(r.h2,{id:"-learning-objectives",children:"\ud83c\udfaf Learning Objectives"}),"\n",(0,a.jsx)(r.p,{children:"By the end of this project, you will:"}),"\n",(0,a.jsxs)(r.ul,{children:["\n",(0,a.jsx)(r.li,{children:"Create a complete ROS 2 package with multiple nodes and message types"}),"\n",(0,a.jsx)(r.li,{children:"Implement a robot description with URDF and Xacro"}),"\n",(0,a.jsx)(r.li,{children:"Build launch files for different operational modes"}),"\n",(0,a.jsx)(r.li,{children:"Integrate services, actions, and parameters for runtime configuration"}),"\n",(0,a.jsx)(r.li,{children:"Test and validate your complete robot system"}),"\n"]}),"\n",(0,a.jsx)(r.h2,{id:"\ufe0f-project-overview-autonomous-delivery-robot",children:"\ud83c\udfd7\ufe0f Project Overview: Autonomous Delivery Robot"}),"\n",(0,a.jsx)(r.p,{children:"You'll build an autonomous delivery robot system that includes:"}),"\n",(0,a.jsxs)(r.ul,{children:["\n",(0,a.jsx)(r.li,{children:"Robot description (URDF/Xacro)"}),"\n",(0,a.jsx)(r.li,{children:"Sensor processing nodes"}),"\n",(0,a.jsx)(r.li,{children:"Navigation and path planning"}),"\n",(0,a.jsx)(r.li,{children:"State machine for delivery operations"}),"\n",(0,a.jsx)(r.li,{children:"Launch files for simulation and real robot"}),"\n",(0,a.jsx)(r.li,{children:"Configuration files and parameters"}),"\n"]}),"\n",(0,a.jsx)(r.admonition,{title:"Did You Know?",type:"info",children:(0,a.jsx)(r.p,{children:"This project combines all the core concepts of ROS 2: nodes, topics, services, actions, parameters, launch files, and URDF."})}),"\n",(0,a.jsx)(r.h3,{id:"package-structure",children:"Package Structure"}),"\n",(0,a.jsx)(r.p,{children:"First, let's create the complete package structure:"}),"\n",(0,a.jsx)(r.pre,{children:(0,a.jsx)(r.code,{children:"delivery_robot/\r\n\u251c\u2500\u2500 CMakeLists.txt\r\n\u251c\u2500\u2500 package.xml\r\n\u251c\u2500\u2500 setup.py\r\n\u251c\u2500\u2500 setup.cfg\r\n\u251c\u2500\u2500 resource/delivery_robot\r\n\u251c\u2500\u2500 delivery_robot/\r\n\u2502   \u251c\u2500\u2500 __init__.py\r\n\u2502   \u251c\u2500\u2500 robot_controller.py\r\n\u2502   \u251c\u2500\u2500 sensor_processor.py\r\n\u2502   \u251c\u2500\u2500 delivery_state_machine.py\r\n\u2502   \u2514\u2500\u2500 utils/\r\n\u2502       \u251c\u2500\u2500 __init__.py\r\n\u2502       \u2514\u2500\u2500 robot_helpers.py\r\n\u251c\u2500\u2500 launch/\r\n\u2502   \u251c\u2500\u2500 delivery_robot.launch.py\r\n\u2502   \u251c\u2500\u2500 simulation.launch.py\r\n\u2502   \u2514\u2500\u2500 real_robot.launch.py\r\n\u251c\u2500\u2500 config/\r\n\u2502   \u251c\u2500\u2500 robot_params.yaml\r\n\u2502   \u251c\u2500\u2500 navigation_params.yaml\r\n\u2502   \u2514\u2500\u2500 sensors_params.yaml\r\n\u251c\u2500\u2500 urdf/\r\n\u2502   \u251c\u2500\u2500 robot.urdf.xacro\r\n\u2502   \u251c\u2500\u2500 materials.xacro\r\n\u2502   \u2514\u2500\u2500 sensors.xacro\r\n\u251c\u2500\u2500 msg/\r\n\u2502   \u2514\u2500\u2500 DeliveryStatus.msg\r\n\u251c\u2500\u2500 srv/\r\n\u2502   \u2514\u2500\u2500 RequestDelivery.srv\r\n\u251c\u2500\u2500 action/\r\n\u2502   \u2514\u2500\u2500 DeliverItem.action\r\n\u2514\u2500\u2500 rviz/\r\n    \u2514\u2500\u2500 robot_view.rviz\n"})}),"\n",(0,a.jsx)(r.h2,{id:"-creating-the-package-files",children:"\ud83d\udd27 Creating the Package Files"}),"\n",(0,a.jsx)(r.h3,{id:"1-package-manifest-packagexml",children:"1. Package Manifest (package.xml)"}),"\n",(0,a.jsx)(r.pre,{children:(0,a.jsx)(r.code,{className:"language-xml",children:'<?xml version="1.0"?>\r\n<?xml-model href="http://download.ros.org/schema/package_format3.xsd" schematypens="http://www.w3.org/2001/XMLSchema"?>\r\n<package format="3">\r\n  <name>delivery_robot</name>\r\n  <version>1.0.0</version>\r\n  <description>Autonomous delivery robot system</description>\r\n  <maintainer email="robotics@example.com">Robotics Team</maintainer>\r\n  <license>Apache-2.0</license>\r\n\r\n  <exec_depend>rclpy</exec_depend>\r\n  <exec_depend>std_msgs</exec_depend>\r\n  <exec_depend>geometry_msgs</exec_depend>\r\n  <exec_depend>sensor_msgs</exec_depend>\r\n  <exec_depend>nav_msgs</exec_depend>\r\n  <exec_depend>tf2_ros</exec_depend>\r\n  <exec_depend>robot_state_publisher</exec_depend>\r\n  <exec_depend>joint_state_publisher</exec_depend>\r\n  <exec_depend>rviz2</exec_depend>\r\n\r\n  <test_depend>ament_copyright</test_depend>\r\n  <test_depend>ament_flake8</test_depend>\r\n  <test_depend>ament_pep257</test_depend>\r\n  <test_depend>python3-pytest</test_depend>\r\n\r\n  <export>\r\n    <build_type>ament_python</build_type>\r\n  </export>\r\n</package>\n'})}),"\n",(0,a.jsx)(r.h3,{id:"2-setup-configuration-setuppy",children:"2. Setup Configuration (setup.py)"}),"\n",(0,a.jsx)(r.pre,{children:(0,a.jsx)(r.code,{className:"language-python",children:"from setuptools import setup\r\nfrom glob import glob\r\nimport os\r\n\r\npackage_name = 'delivery_robot'\r\n\r\nsetup(\r\n    name=package_name,\r\n    version='1.0.0',\r\n    packages=[package_name],\r\n    data_files=[\r\n        ('share/ament_index/resource_index/packages',\r\n            ['resource/' + package_name]),\r\n        ('share/' + package_name, ['package.xml']),\r\n        # Include launch files\r\n        (os.path.join('share', package_name, 'launch'), glob('launch/*.launch.py')),\r\n        # Include config files\r\n        (os.path.join('share', package_name, 'config'), glob('config/*.yaml')),\r\n        # Include URDF files\r\n        (os.path.join('share', package_name, 'urdf'), glob('urdf/*.xacro')),\r\n        (os.path.join('share', package_name, 'urdf'), glob('urdf/*.urdf')),\r\n        # Include RViz config\r\n        (os.path.join('share', package_name, 'rviz'), glob('rviz/*.rviz')),\r\n    ],\r\n    install_requires=['setuptools'],\r\n    zip_safe=True,\r\n    maintainer='Robotics Team',\r\n    maintainer_email='robotics@example.com',\r\n    description='Autonomous delivery robot system',\r\n    license='Apache-2.0',\r\n    tests_require=['pytest'],\r\n    entry_points={\r\n        'console_scripts': [\r\n            'robot_controller = delivery_robot.robot_controller:main',\r\n            'sensor_processor = delivery_robot.sensor_processor:main',\r\n            'delivery_state_machine = delivery_robot.delivery_state_machine:main',\r\n        ],\r\n    },\r\n)\n"})}),"\n",(0,a.jsx)(r.h3,{id:"3-robot-description-urdfxacro",children:"3. Robot Description (URDF/Xacro)"}),"\n",(0,a.jsx)(r.pre,{children:(0,a.jsx)(r.code,{className:"language-xml",children:'<?xml version="1.0"?>\r\n<robot xmlns:xacro="http://www.ros.org/wiki/xacro" name="delivery_robot">\r\n\r\n  \x3c!-- Properties --\x3e\r\n  <xacro:property name="M_PI" value="3.1415926535897931" />\r\n  <xacro:property name="base_width" value="0.6" />\r\n  <xacro:property name="base_length" value="0.8" />\r\n  <xacro:property name="base_height" value="0.3" />\r\n  <xacro:property name="wheel_radius" value="0.15" />\r\n  <xacro:property name="wheel_width" value="0.05" />\r\n  <xacro:property name="wheel_offset_x" value="0.3" />\r\n  <xacro:property name="wheel_offset_y" value="0.3" />\r\n\r\n  \x3c!-- Materials --\x3e\r\n  <material name="blue">\r\n    <color rgba="0.0 0.0 0.8 1.0"/>\r\n  </material>\r\n  <material name="black">\r\n    <color rgba="0.0 0.0 0.0 1.0"/>\r\n  </material>\r\n  <material name="white">\r\n    <color rgba="1.0 1.0 1.0 1.0"/>\r\n  </material>\r\n\r\n  \x3c!-- Base Link --\x3e\r\n  <link name="base_link">\r\n    <visual>\r\n      <geometry>\r\n        <box size="${base_length} ${base_width} ${base_height}"/>\r\n      </geometry>\r\n      <material name="blue"/>\r\n    </visual>\r\n    <collision>\r\n      <geometry>\r\n        <box size="${base_length} ${base_width} ${base_height}"/>\r\n      </geometry>\r\n    </collision>\r\n    <inertial>\r\n      <mass value="10.0"/>\r\n      <inertia ixx="1.0" ixy="0.0" ixz="0.0"\r\n               iyy="1.0" iyz="0.0" izz="1.0"/>\r\n    </inertial>\r\n  </link>\r\n\r\n  \x3c!-- Wheels --\x3e\r\n  <xacro:macro name="wheel" params="prefix x_reflect y_reflect">\r\n    <link name="${prefix}_wheel">\r\n      <visual>\r\n        <geometry>\r\n          <cylinder radius="${wheel_radius}" length="${wheel_width}"/>\r\n        </geometry>\r\n        <material name="black"/>\r\n      </visual>\r\n      <collision>\r\n        <geometry>\r\n          <cylinder radius="${wheel_radius}" length="${wheel_width}"/>\r\n        </geometry>\r\n      </collision>\r\n      <inertial>\r\n        <mass value="0.5"/>\r\n        <inertia ixx="0.01" ixy="0.0" ixz="0.0"\r\n                 iyy="0.01" iyz="0.0" izz="0.01"/>\r\n      </inertial>\r\n    </link>\r\n\r\n    <joint name="${prefix}_wheel_joint" type="continuous">\r\n      <parent link="base_link"/>\r\n      <child link="${prefix}_wheel"/>\r\n      <origin xyz="${x_reflect * wheel_offset_x} ${y_reflect * wheel_offset_y} -${wheel_radius}"\r\n              rpy="${M_PI/2} 0 0"/>\r\n      <axis xyz="0 0 1"/>\r\n    </joint>\r\n  </xacro:macro>\r\n\r\n  <xacro:wheel prefix="front_left" x_reflect="1" y_reflect="1"/>\r\n  <xacro:wheel prefix="front_right" x_reflect="1" y_reflect="-1"/>\r\n  <xacro:wheel prefix="rear_left" x_reflect="-1" y_reflect="1"/>\r\n  <xacro:wheel prefix="rear_right" x_reflect="-1" y_reflect="-1"/>\r\n\r\n  \x3c!-- Camera --\x3e\r\n  <link name="camera_link">\r\n    <visual>\r\n      <geometry>\r\n        <box size="0.05 0.05 0.05"/>\r\n      </geometry>\r\n      <material name="white"/>\r\n    </visual>\r\n    <collision>\r\n      <geometry>\r\n        <box size="0.05 0.05 0.05"/>\r\n      </geometry>\r\n    </collision>\r\n    <inertial>\r\n      <mass value="0.1"/>\r\n      <inertia ixx="0.001" ixy="0.0" ixz="0.0"\r\n               iyy="0.001" iyz="0.0" izz="0.001"/>\r\n    </inertial>\r\n  </link>\r\n\r\n  <joint name="camera_joint" type="fixed">\r\n    <parent link="base_link"/>\r\n    <child link="camera_link"/>\r\n    <origin xyz="${base_length/2 - 0.05} 0 ${base_height/2}" rpy="0 0 0"/>\r\n  </joint>\r\n\r\n  \x3c!-- LiDAR --\x3e\r\n  <link name="lidar_link">\r\n    <visual>\r\n      <geometry>\r\n        <cylinder radius="0.05" length="0.05"/>\r\n      </geometry>\r\n      <material name="black"/>\r\n    </visual>\r\n    <collision>\r\n      <geometry>\r\n        <cylinder radius="0.05" length="0.05"/>\r\n      </geometry>\r\n    </collision>\r\n    <inertial>\r\n      <mass value="0.2"/>\r\n      <inertia ixx="0.002" ixy="0.0" ixz="0.0"\r\n               iyy="0.002" iyz="0.0" izz="0.002"/>\r\n    </inertial>\r\n  </link>\r\n\r\n  <joint name="lidar_joint" type="fixed">\r\n    <parent link="base_link"/>\r\n    <child link="lidar_link"/>\r\n    <origin xyz="0 0 ${base_height/2 + 0.05}" rpy="0 0 0"/>\r\n  </joint>\r\n\r\n</robot>\n'})}),"\n",(0,a.jsx)(r.h3,{id:"4-main-robot-controller-node",children:"4. Main Robot Controller Node"}),"\n",(0,a.jsx)(r.pre,{children:(0,a.jsx)(r.code,{className:"language-python",children:'# delivery_robot/robot_controller.py\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom geometry_msgs.msg import Twist, Pose\r\nfrom sensor_msgs.msg import LaserScan\r\nfrom nav_msgs.msg import Odometry\r\nfrom std_msgs.msg import String\r\nfrom rclpy.qos import QoSProfile\r\nfrom rclpy.action import ActionClient\r\nfrom rclpy.parameter import Parameter\r\nfrom tf2_ros import TransformBroadcaster\r\nimport math\r\nimport numpy as np\r\n\r\nclass RobotController(Node):\r\n    def __init__(self):\r\n        super().__init__(\'robot_controller\')\r\n\r\n        # Declare parameters\r\n        self.declare_parameter(\'max_linear_velocity\', 0.5)\r\n        self.declare_parameter(\'max_angular_velocity\', 1.0)\r\n        self.declare_parameter(\'safety_distance\', 0.5)\r\n        self.declare_parameter(\'robot_radius\', 0.3)\r\n\r\n        # Get parameter values\r\n        self.max_linear_vel = self.get_parameter(\'max_linear_velocity\').value\r\n        self.max_angular_vel = self.get_parameter(\'max_angular_velocity\').value\r\n        self.safety_distance = self.get_parameter(\'safety_distance\').value\r\n        self.robot_radius = self.get_parameter(\'robot_radius\').value\r\n\r\n        # Publishers\r\n        self.cmd_vel_pub = self.create_publisher(Twist, \'cmd_vel\', 10)\r\n        self.status_pub = self.create_publisher(String, \'robot_status\', 10)\r\n\r\n        # Subscribers\r\n        self.scan_sub = self.create_subscription(\r\n            LaserScan, \'scan\', self.scan_callback, 10\r\n        )\r\n        self.odom_sub = self.create_subscription(\r\n            Odometry, \'odom\', self.odom_callback, 10\r\n        )\r\n\r\n        # Timer for control loop\r\n        self.control_timer = self.create_timer(0.1, self.control_loop)\r\n\r\n        # Robot state\r\n        self.current_pose = Pose()\r\n        self.current_twist = Twist()\r\n        self.scan_data = None\r\n        self.emergency_stop = False\r\n        self.target_pose = None\r\n\r\n        # TF broadcaster\r\n        self.tf_broadcaster = TransformBroadcaster(self)\r\n\r\n        self.get_logger().info(\'Robot Controller initialized\')\r\n\r\n    def odom_callback(self, msg):\r\n        """Update robot pose from odometry"""\r\n        self.current_pose = msg.pose.pose\r\n        self.current_twist = msg.twist.twist\r\n\r\n    def scan_callback(self, msg):\r\n        """Process laser scan data"""\r\n        self.scan_data = msg\r\n\r\n    def control_loop(self):\r\n        """Main control loop"""\r\n        if self.scan_data is None:\r\n            return\r\n\r\n        # Check for obstacles\r\n        if self.check_obstacles():\r\n            cmd_vel = Twist()\r\n            cmd_vel.linear.x = 0.0\r\n            cmd_vel.angular.z = 0.0\r\n            self.emergency_stop = True\r\n        else:\r\n            # Calculate control command based on target\r\n            cmd_vel = self.calculate_control_command()\r\n            self.emergency_stop = False\r\n\r\n        # Publish command\r\n        self.cmd_vel_pub.publish(cmd_vel)\r\n\r\n        # Publish status\r\n        status_msg = String()\r\n        status_msg.data = \'EMERGENCY_STOP\' if self.emergency_stop else \'NORMAL\'\r\n        self.status_pub.publish(status_msg)\r\n\r\n    def check_obstacles(self):\r\n        """Check for obstacles in the robot\'s path"""\r\n        if self.scan_data is None:\r\n            return False\r\n\r\n        # Check front sector (\xb130 degrees)\r\n        front_start = len(self.scan_data.ranges) // 2 - 30\r\n        front_end = len(self.scan_data.ranges) // 2 + 30\r\n\r\n        if front_start < 0:\r\n            front_start = 0\r\n        if front_end >= len(self.scan_data.ranges):\r\n            front_end = len(self.scan_data.ranges) - 1\r\n\r\n        for i in range(front_start, front_end):\r\n            if (self.scan_data.ranges[i] < self.safety_distance and\r\n                not math.isnan(self.scan_data.ranges[i]) and\r\n                not math.isinf(self.scan_data.ranges[i])):\r\n                return True\r\n\r\n        return False\r\n\r\n    def calculate_control_command(self):\r\n        """Calculate velocity command to reach target"""\r\n        cmd_vel = Twist()\r\n\r\n        if self.target_pose is None:\r\n            return cmd_vel\r\n\r\n        # Calculate distance and angle to target\r\n        dx = self.target_pose.position.x - self.current_pose.position.x\r\n        dy = self.target_pose.position.y - self.current_pose.position.y\r\n        distance = math.sqrt(dx*dx + dy*dy)\r\n\r\n        # Calculate target angle\r\n        target_angle = math.atan2(dy, dx)\r\n        current_angle = self.get_yaw_from_quaternion(self.current_pose.orientation)\r\n\r\n        # Calculate angle difference\r\n        angle_diff = target_angle - current_angle\r\n        # Normalize angle to [-\u03c0, \u03c0]\r\n        while angle_diff > math.pi:\r\n            angle_diff -= 2 * math.pi\r\n        while angle_diff < -math.pi:\r\n            angle_diff += 2 * math.pi\r\n\r\n        # PID-like control\r\n        angular_kp = 1.0\r\n        linear_kp = 0.5\r\n\r\n        # Rotate to face target if not aligned\r\n        if abs(angle_diff) > 0.1:  # 0.1 rad = ~5.7 degrees\r\n            cmd_vel.angular.z = max(-self.max_angular_vel,\r\n                                  min(self.max_angular_vel,\r\n                                      angular_kp * angle_diff))\r\n        elif distance > 0.1:  # 0.1m threshold\r\n            cmd_vel.linear.x = max(0.0,\r\n                                 min(self.max_linear_vel,\r\n                                     linear_kp * distance))\r\n\r\n        return cmd_vel\r\n\r\n    def get_yaw_from_quaternion(self, quaternion):\r\n        """Extract yaw from quaternion"""\r\n        siny_cosp = 2 * (quaternion.w * quaternion.z + quaternion.x * quaternion.y)\r\n        cosy_cosp = 1 - 2 * (quaternion.y * quaternion.y + quaternion.z * quaternion.z)\r\n        return math.atan2(siny_cosp, cosy_cosp)\r\n\r\n    def set_target(self, target_pose):\r\n        """Set navigation target"""\r\n        self.target_pose = target_pose\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n\r\n    robot_controller = RobotController()\r\n\r\n    try:\r\n        rclpy.spin(robot_controller)\r\n    except KeyboardInterrupt:\r\n        pass\r\n    finally:\r\n        robot_controller.destroy_node()\r\n        rclpy.shutdown()\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n",(0,a.jsx)(r.h3,{id:"5-sensor-processing-node",children:"5. Sensor Processing Node"}),"\n",(0,a.jsx)(r.pre,{children:(0,a.jsx)(r.code,{className:"language-python",children:'# delivery_robot/sensor_processor.py\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom sensor_msgs.msg import LaserScan, Image, PointCloud2\r\nfrom geometry_msgs.msg import PointStamped\r\nfrom std_msgs.msg import Header\r\nfrom cv_bridge import CvBridge\r\nimport cv2\r\nimport numpy as np\r\nfrom rclpy.qos import QoSProfile, ReliabilityPolicy, HistoryPolicy\r\n\r\nclass SensorProcessor(Node):\r\n    def __init__(self):\r\n        super().__init__(\'sensor_processor\')\r\n\r\n        # Declare parameters\r\n        self.declare_parameter(\'processing_rate\', 10.0)\r\n        self.declare_parameter(\'detection_threshold\', 0.5)\r\n\r\n        # Get parameter values\r\n        self.processing_rate = self.get_parameter(\'processing_rate\').value\r\n        self.detection_threshold = self.get_parameter(\'detection_threshold\').value\r\n\r\n        # Publishers\r\n        self.object_pub = self.create_publisher(PointStamped, \'detected_object\', 10)\r\n        self.processed_scan_pub = self.create_publisher(LaserScan, \'processed_scan\', 10)\r\n\r\n        # Subscribers\r\n        self.scan_sub = self.create_subscription(\r\n            LaserScan, \'scan\', self.scan_callback, 10\r\n        )\r\n        self.image_sub = self.create_subscription(\r\n            Image, \'camera/image_raw\', self.image_callback, 10\r\n        )\r\n\r\n        # CV Bridge for image processing\r\n        self.cv_bridge = CvBridge()\r\n\r\n        # Timer for processing\r\n        self.process_timer = self.create_timer(1.0/self.processing_rate, self.process_sensors)\r\n\r\n        # Sensor data storage\r\n        self.latest_scan = None\r\n        self.latest_image = None\r\n        self.objects_detected = []\r\n\r\n        self.get_logger().info(\'Sensor Processor initialized\')\r\n\r\n    def scan_callback(self, msg):\r\n        """Store latest laser scan data"""\r\n        self.latest_scan = msg\r\n\r\n    def image_callback(self, msg):\r\n        """Process camera image"""\r\n        try:\r\n            cv_image = self.cv_bridge.imgmsg_to_cv2(msg, desired_encoding=\'bgr8\')\r\n            self.process_image(cv_image)\r\n        except Exception as e:\r\n            self.get_logger().error(f\'Error processing image: {e}\')\r\n\r\n    def process_sensors(self):\r\n        """Process sensor data and detect objects"""\r\n        if self.latest_scan is not None:\r\n            # Process laser scan for obstacles\r\n            processed_scan = self.process_laser_scan(self.latest_scan)\r\n            self.processed_scan_pub.publish(processed_scan)\r\n\r\n        if self.latest_image is not None:\r\n            # Process image for object detection\r\n            self.detect_objects_in_image(self.latest_image)\r\n\r\n    def process_laser_scan(self, scan_msg):\r\n        """Process laser scan data"""\r\n        # Create a copy of the scan with processed data\r\n        processed_scan = LaserScan()\r\n        processed_scan.header = scan_msg.header\r\n        processed_scan.angle_min = scan_msg.angle_min\r\n        processed_scan.angle_max = scan_msg.angle_max\r\n        processed_scan.angle_increment = scan_msg.angle_increment\r\n        processed_scan.time_increment = scan_msg.time_increment\r\n        processed_scan.scan_time = scan_msg.scan_time\r\n        processed_scan.range_min = scan_msg.range_min\r\n        processed_scan.range_max = scan_msg.range_max\r\n\r\n        # Process ranges - for example, remove invalid readings\r\n        processed_ranges = []\r\n        for r in scan_msg.ranges:\r\n            if r < scan_msg.range_min or r > scan_msg.range_max or np.isnan(r):\r\n                processed_ranges.append(float(\'inf\'))  # Mark as invalid\r\n            else:\r\n                processed_ranges.append(r)\r\n\r\n        processed_scan.ranges = processed_ranges\r\n        processed_scan.intensities = scan_msg.intensities\r\n\r\n        return processed_scan\r\n\r\n    def process_image(self, cv_image):\r\n        """Process image for basic features"""\r\n        # Convert to grayscale\r\n        gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)\r\n\r\n        # Apply Gaussian blur\r\n        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\r\n\r\n        # Apply Canny edge detection\r\n        edges = cv2.Canny(blurred, 50, 150)\r\n\r\n        # Find contours\r\n        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\r\n\r\n        # Process contours (objects)\r\n        for contour in contours:\r\n            area = cv2.contourArea(contour)\r\n            if area > 100:  # Filter small contours\r\n                # Get bounding box\r\n                x, y, w, h = cv2.boundingRect(contour)\r\n\r\n                # Calculate center\r\n                center_x = x + w // 2\r\n                center_y = y + h // 2\r\n\r\n                # Create point message\r\n                point_msg = PointStamped()\r\n                point_msg.header = Header()\r\n                point_msg.header.stamp = self.get_clock().now().to_msg()\r\n                point_msg.header.frame_id = \'camera_link\'\r\n                point_msg.point.x = center_x\r\n                point_msg.point.y = center_y\r\n                point_msg.point.z = 0.0  # Depth would come from stereo/depth camera\r\n\r\n                # Publish detected object\r\n                self.object_pub.publish(point_msg)\r\n\r\n    def detect_objects_in_image(self, image_msg):\r\n        """Object detection in image (placeholder for more complex detection)"""\r\n        # This would typically use a neural network or computer vision algorithm\r\n        # For now, we\'ll use the basic image processing above\r\n        pass\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n\r\n    sensor_processor = SensorProcessor()\r\n\r\n    try:\r\n        rclpy.spin(sensor_processor)\r\n    except KeyboardInterrupt:\r\n        pass\r\n    finally:\r\n        sensor_processor.destroy_node()\r\n        rclpy.shutdown()\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n",(0,a.jsx)(r.h3,{id:"6-delivery-state-machine-node",children:"6. Delivery State Machine Node"}),"\n",(0,a.jsx)(r.pre,{children:(0,a.jsx)(r.code,{className:"language-python",children:'# delivery_robot/delivery_state_machine.py\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom std_msgs.msg import String, Bool\r\nfrom geometry_msgs.msg import Pose\r\nfrom rclpy.action import ActionClient\r\nfrom rclpy.callback_groups import MutuallyExclusiveCallbackGroup\r\nfrom rclpy.qos import QoSProfile\r\nfrom enum import Enum\r\nimport time\r\n\r\nclass DeliveryState(Enum):\r\n    IDLE = 1\r\n    NAVIGATING_TO_PICKUP = 2\r\n    WAITING_AT_PICKUP = 3\r\n    NAVIGATING_TO_DELIVERY = 4\r\n    WAITING_AT_DELIVERY = 5\r\n    RETURNING_TO_BASE = 6\r\n    EMERGENCY_STOP = 7\r\n\r\nclass DeliveryStateMachine(Node):\r\n    def __init__(self):\r\n        super().__init__(\'delivery_state_machine\')\r\n\r\n        # State management\r\n        self.current_state = DeliveryState.IDLE\r\n        self.previous_state = None\r\n\r\n        # Declare parameters\r\n        self.declare_parameter(\'delivery_timeout\', 300)  # 5 minutes\r\n        self.declare_parameter(\'pickup_timeout\', 120)   # 2 minutes\r\n\r\n        # Get parameter values\r\n        self.delivery_timeout = self.get_parameter(\'delivery_timeout\').value\r\n        self.pickup_timeout = self.get_parameter(\'pickup_timeout\').value\r\n\r\n        # Publishers\r\n        self.state_pub = self.create_publisher(String, \'delivery_state\', 10)\r\n        self.emergency_pub = self.create_publisher(Bool, \'emergency_stop\', 10)\r\n\r\n        # Subscribers\r\n        self.command_sub = self.create_subscription(\r\n            String, \'delivery_command\', self.command_callback, 10\r\n        )\r\n        self.status_sub = self.create_subscription(\r\n            String, \'robot_status\', self.status_callback, 10\r\n        )\r\n\r\n        # Timer for state processing\r\n        self.state_timer = self.create_timer(0.1, self.state_machine_callback)\r\n\r\n        # Delivery information\r\n        self.delivery_queue = []\r\n        self.current_delivery = None\r\n        self.pickup_location = Pose()\r\n        self.delivery_location = Pose()\r\n        self.base_location = Pose()\r\n\r\n        # Timers for timeouts\r\n        self.delivery_start_time = None\r\n        self.pickup_start_time = None\r\n\r\n        self.get_logger().info(\'Delivery State Machine initialized\')\r\n\r\n    def command_callback(self, msg):\r\n        """Handle delivery commands"""\r\n        command = msg.data.lower()\r\n\r\n        if command.startswith(\'deliver_to:\'):\r\n            # Parse delivery location from command\r\n            # Format: "deliver_to:x,y,z"\r\n            try:\r\n                coords = command.split(\':\')[1].split(\',\')\r\n                x, y, z = float(coords[0]), float(coords[1]), float(coords[2])\r\n\r\n                # Set delivery location\r\n                self.delivery_location.position.x = x\r\n                self.delivery_location.position.y = y\r\n                self.delivery_location.position.z = z\r\n\r\n                # Start delivery process\r\n                if self.current_state == DeliveryState.IDLE:\r\n                    self.current_state = DeliveryState.NAVIGATING_TO_PICKUP\r\n                    self.delivery_start_time = time.time()\r\n                    self.get_logger().info(f\'Starting delivery to ({x}, {y}, {z})\')\r\n            except Exception as e:\r\n                self.get_logger().error(f\'Error parsing delivery command: {e}\')\r\n\r\n        elif command == \'emergency_stop\':\r\n            self.current_state = DeliveryState.EMERGENCY_STOP\r\n            self.emergency_stop()\r\n\r\n        elif command == \'resume\':\r\n            if self.current_state == DeliveryState.EMERGENCY_STOP:\r\n                self.current_state = DeliveryState.IDLE\r\n                self.get_logger().info(\'Resuming from emergency stop\')\r\n\r\n    def status_callback(self, msg):\r\n        """Handle robot status updates"""\r\n        status = msg.data\r\n\r\n        # If robot reports emergency stop, update our state\r\n        if status == \'EMERGENCY_STOP\' and self.current_state != DeliveryState.EMERGENCY_STOP:\r\n            self.current_state = DeliveryState.EMERGENCY_STOP\r\n            self.emergency_stop()\r\n\r\n    def state_machine_callback(self):\r\n        """Main state machine processing"""\r\n        if self.current_state != self.previous_state:\r\n            self.handle_state_transition()\r\n            self.previous_state = self.current_state\r\n\r\n        # Process current state\r\n        if self.current_state == DeliveryState.IDLE:\r\n            self.process_idle_state()\r\n        elif self.current_state == DeliveryState.NAVIGATING_TO_PICKUP:\r\n            self.process_navigating_to_pickup_state()\r\n        elif self.current_state == DeliveryState.WAITING_AT_PICKUP:\r\n            self.process_waiting_at_pickup_state()\r\n        elif self.current_state == DeliveryState.NAVIGATING_TO_DELIVERY:\r\n            self.process_navigating_to_delivery_state()\r\n        elif self.current_state == DeliveryState.WAITING_AT_DELIVERY:\r\n            self.process_waiting_at_delivery_state()\r\n        elif self.current_state == DeliveryState.RETURNING_TO_BASE:\r\n            self.process_returning_to_base_state()\r\n        elif self.current_state == DeliveryState.EMERGENCY_STOP:\r\n            self.process_emergency_stop_state()\r\n\r\n        # Check for timeouts\r\n        self.check_timeouts()\r\n\r\n        # Publish current state\r\n        state_msg = String()\r\n        state_msg.data = self.current_state.name\r\n        self.state_pub.publish(state_msg)\r\n\r\n    def handle_state_transition(self):\r\n        """Handle actions when entering a new state"""\r\n        if self.current_state == DeliveryState.NAVIGATING_TO_PICKUP:\r\n            self.get_logger().info(\'Navigating to pickup location\')\r\n            self.pickup_start_time = time.time()\r\n        elif self.current_state == DeliveryState.WAITING_AT_PICKUP:\r\n            self.get_logger().info(\'Waiting at pickup location\')\r\n        elif self.current_state == DeliveryState.NAVIGATING_TO_DELIVERY:\r\n            self.get_logger().info(\'Navigating to delivery location\')\r\n        elif self.current_state == DeliveryState.WAITING_AT_DELIVERY:\r\n            self.get_logger().info(\'Waiting at delivery location\')\r\n        elif self.current_state == DeliveryState.RETURNING_TO_BASE:\r\n            self.get_logger().info(\'Returning to base\')\r\n        elif self.current_state == DeliveryState.EMERGENCY_STOP:\r\n            self.emergency_stop()\r\n\r\n    def process_idle_state(self):\r\n        """Process IDLE state"""\r\n        # Wait for delivery command\r\n        pass\r\n\r\n    def process_navigating_to_pickup_state(self):\r\n        """Process navigation to pickup state"""\r\n        # In a real system, this would send navigation goals\r\n        # For simulation, we\'ll assume navigation is happening\r\n        self.get_logger().info(\'Navigating to pickup location...\', throttle_duration_sec=5)\r\n\r\n    def process_waiting_at_pickup_state(self):\r\n        """Process waiting at pickup state"""\r\n        # Wait for pickup confirmation\r\n        # In real system, this would wait for human interaction\r\n        self.get_logger().info(\'Waiting for package pickup...\', throttle_duration_sec=5)\r\n\r\n    def process_navigating_to_delivery_state(self):\r\n        """Process navigation to delivery state"""\r\n        # Navigate to delivery location\r\n        self.get_logger().info(\'Navigating to delivery location...\', throttle_duration_sec=5)\r\n\r\n    def process_waiting_at_delivery_state(self):\r\n        """Process waiting at delivery state"""\r\n        # Wait for delivery confirmation\r\n        self.get_logger().info(\'Waiting for package delivery...\', throttle_duration_sec=5)\r\n\r\n    def process_returning_to_base_state(self):\r\n        """Process returning to base state"""\r\n        # Navigate back to base\r\n        self.get_logger().info(\'Returning to base...\', throttle_duration_sec=5)\r\n\r\n    def process_emergency_stop_state(self):\r\n        """Process emergency stop state"""\r\n        self.emergency_stop()\r\n\r\n    def check_timeouts(self):\r\n        """Check for delivery/pickup timeouts"""\r\n        current_time = time.time()\r\n\r\n        if (self.current_state == DeliveryState.WAITING_AT_PICKUP and\r\n            self.pickup_start_time and\r\n            current_time - self.pickup_start_time > self.pickup_timeout):\r\n            self.get_logger().warn(\'Pickup timeout - returning to base\')\r\n            self.current_state = DeliveryState.RETURNING_TO_BASE\r\n\r\n        if (self.current_state == DeliveryState.WAITING_AT_DELIVERY and\r\n            self.delivery_start_time and\r\n            current_time - self.delivery_start_time > self.delivery_timeout):\r\n            self.get_logger().warn(\'Delivery timeout - returning to base\')\r\n            self.current_state = DeliveryState.RETURNING_TO_BASE\r\n\r\n    def emergency_stop(self):\r\n        """Send emergency stop command"""\r\n        emergency_msg = Bool()\r\n        emergency_msg.data = True\r\n        self.emergency_pub.publish(emergency_msg)\r\n        self.get_logger().warn(\'Emergency stop activated!\')\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n\r\n    delivery_state_machine = DeliveryStateMachine()\r\n\r\n    try:\r\n        rclpy.spin(delivery_state_machine)\r\n    except KeyboardInterrupt:\r\n        pass\r\n    finally:\r\n        delivery_state_machine.destroy_node()\r\n        rclpy.shutdown()\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n",(0,a.jsx)(r.h3,{id:"7-launch-file-for-the-complete-system",children:"7. Launch File for the Complete System"}),"\n",(0,a.jsx)(r.pre,{children:(0,a.jsx)(r.code,{className:"language-python",children:"# launch/delivery_robot.launch.py\r\nfrom launch import LaunchDescription\r\nfrom launch.actions import DeclareLaunchArgument, IncludeLaunchDescription, GroupAction\r\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\r\nfrom launch.substitutions import LaunchConfiguration, PathJoinSubstitution\r\nfrom launch_ros.actions import Node, PushRosNamespace\r\nfrom launch_ros.substitutions import FindPackageShare\r\nfrom ament_index_python.packages import get_package_share_directory\r\nimport os\r\n\r\ndef generate_launch_description():\r\n    # Launch arguments\r\n    use_sim_time = DeclareLaunchArgument(\r\n        'use_sim_time',\r\n        default_value='false',\r\n        description='Use simulation clock if true'\r\n    )\r\n\r\n    robot_namespace = DeclareLaunchArgument(\r\n        'robot_namespace',\r\n        default_value='delivery_robot',\r\n        description='Robot namespace for multi-robot systems'\r\n    )\r\n\r\n    # Robot description parameter\r\n    robot_description = DeclareLaunchArgument(\r\n        'robot_description',\r\n        default_value=PathJoinSubstitution([\r\n            FindPackageShare('delivery_robot'),\r\n            'urdf',\r\n            'robot.urdf.xacro'\r\n        ]),\r\n        description='Full path to robot description file to load'\r\n    )\r\n\r\n    # Robot state publisher node\r\n    robot_state_publisher = Node(\r\n        package='robot_state_publisher',\r\n        executable='robot_state_publisher',\r\n        name='robot_state_publisher',\r\n        parameters=[\r\n            {'use_sim_time': LaunchConfiguration('use_sim_time')},\r\n            {'robot_description': LaunchConfiguration('robot_description')}\r\n        ],\r\n        remappings=[\r\n            ('/tf', 'tf'),\r\n            ('/tf_static', 'tf_static')\r\n        ]\r\n    )\r\n\r\n    # Joint state publisher (for simulation)\r\n    joint_state_publisher = Node(\r\n        package='joint_state_publisher',\r\n        executable='joint_state_publisher',\r\n        name='joint_state_publisher',\r\n        parameters=[\r\n            {'use_sim_time': LaunchConfiguration('use_sim_time')}\r\n        ]\r\n    )\r\n\r\n    # Robot controller node\r\n    robot_controller = Node(\r\n        package='delivery_robot',\r\n        executable='robot_controller',\r\n        name='robot_controller',\r\n        parameters=[\r\n            {'use_sim_time': LaunchConfiguration('use_sim_time')},\r\n            PathJoinSubstitution([\r\n                FindPackageShare('delivery_robot'),\r\n                'config',\r\n                'robot_params.yaml'\r\n            ])\r\n        ],\r\n        remappings=[\r\n            ('cmd_vel', 'cmd_vel'),\r\n            ('odom', 'odom'),\r\n            ('scan', 'scan')\r\n        ]\r\n    )\r\n\r\n    # Sensor processor node\r\n    sensor_processor = Node(\r\n        package='delivery_robot',\r\n        executable='sensor_processor',\r\n        name='sensor_processor',\r\n        parameters=[\r\n            {'use_sim_time': LaunchConfiguration('use_sim_time')},\r\n            PathJoinSubstitution([\r\n                FindPackageShare('delivery_robot'),\r\n                'config',\r\n                'sensors_params.yaml'\r\n            ])\r\n        ],\r\n        remappings=[\r\n            ('camera/image_raw', 'camera/image_raw'),\r\n            ('scan', 'scan')\r\n        ]\r\n    )\r\n\r\n    # Delivery state machine node\r\n    delivery_state_machine = Node(\r\n        package='delivery_robot',\r\n        executable='delivery_state_machine',\r\n        name='delivery_state_machine',\r\n        parameters=[\r\n            {'use_sim_time': LaunchConfiguration('use_sim_time')}\r\n        ],\r\n        remappings=[\r\n            ('delivery_command', 'delivery_command'),\r\n            ('robot_status', 'robot_status')\r\n        ]\r\n    )\r\n\r\n    # RViz node\r\n    rviz = Node(\r\n        package='rviz2',\r\n        executable='rviz2',\r\n        name='rviz2',\r\n        arguments=['-d', PathJoinSubstitution([\r\n            FindPackageShare('delivery_robot'),\r\n            'rviz',\r\n            'robot_view.rviz'\r\n        ])],\r\n        parameters=[\r\n            {'use_sim_time': LaunchConfiguration('use_sim_time')}\r\n        ]\r\n    )\r\n\r\n    # Create launch description\r\n    ld = LaunchDescription()\r\n\r\n    # Add launch arguments\r\n    ld.add_action(use_sim_time)\r\n    ld.add_action(robot_namespace)\r\n    ld.add_action(robot_description)\r\n\r\n    # Add nodes\r\n    ld.add_action(robot_state_publisher)\r\n    ld.add_action(joint_state_publisher)\r\n    ld.add_action(robot_controller)\r\n    ld.add_action(sensor_processor)\r\n    ld.add_action(delivery_state_machine)\r\n    ld.add_action(rviz)\r\n\r\n    return ld\n"})}),"\n",(0,a.jsx)(r.h3,{id:"8-configuration-files",children:"8. Configuration Files"}),"\n",(0,a.jsx)(r.pre,{children:(0,a.jsx)(r.code,{className:"language-yaml",children:"# config/robot_params.yaml\r\ndelivery_robot:\r\n  robot_controller:\r\n    ros__parameters:\r\n      max_linear_velocity: 0.5\r\n      max_angular_velocity: 1.0\r\n      safety_distance: 0.5\r\n      robot_radius: 0.3\n"})}),"\n",(0,a.jsx)(r.pre,{children:(0,a.jsx)(r.code,{className:"language-yaml",children:"# config/sensors_params.yaml\r\ndelivery_robot:\r\n  sensor_processor:\r\n    ros__parameters:\r\n      processing_rate: 10.0\r\n      detection_threshold: 0.5\n"})}),"\n",(0,a.jsx)(r.h3,{id:"9-rviz-configuration",children:"9. RViz Configuration"}),"\n",(0,a.jsx)(r.pre,{children:(0,a.jsx)(r.code,{className:"language-yaml",children:'# rviz/robot_view.rviz\r\nPanels:\r\n  - Class: rviz_common/Displays\r\n    Help Height: 78\r\n    Name: Displays\r\n    Property Tree Widget:\r\n      Expanded:\r\n        - /Global Options1\r\n        - /Status1\r\n        - /RobotModel1\r\n        - /LaserScan1\r\n      Splitter Ratio: 0.5\r\n    Tree Height: 617\r\n  - Class: rviz_common/Selection\r\n    Name: Selection\r\n  - Class: rviz_common/Tool Properties\r\n    Expanded:\r\n      - /2D Goal Pose1\r\n      - /Publish Point1\r\n    Name: Tool Properties\r\n    Splitter Ratio: 0.5886790156364441\r\n  - Class: rviz_common/Views\r\n    Expanded:\r\n      - /Current View1\r\n    Name: Views\r\n    Splitter Ratio: 0.5\r\nVisualization Manager:\r\n  Class: ""\r\n  Displays:\r\n    - Alpha: 0.5\r\n      Cell Size: 1\r\n      Class: rviz_default_plugins/Grid\r\n      Color: 160; 160; 164\r\n      Enabled: true\r\n      Line Style:\r\n        Line Width: 0.029999999329447746\r\n        Value: Lines\r\n      Name: Grid\r\n      Normal Cell Count: 0\r\n      Offset:\r\n        X: 0\r\n        Y: 0\r\n        Z: 0\r\n      Plane: XY\r\n      Plane Cell Count: 10\r\n      Reference Frame: <Fixed Frame>\r\n      Value: true\r\n    - Class: rviz_default_plugins/RobotModel\r\n      Enabled: true\r\n      Name: RobotModel\r\n      Description Topic:\r\n        Value: /robot_description\r\n      Visual Enabled: true\r\n      Collision Enabled: false\r\n      TF Prefix: ""\r\n      Update Interval: 0\r\n      Alpha: 1\r\n      Show Axes: false\r\n      Show Trail: false\r\n      Value: true\r\n    - Alpha: 1\r\n      Autocompute Intensity Bounds: true\r\n      Autocompute Value Bounds:\r\n        Max Value: 10\r\n        Min Value: -10\r\n        Value: true\r\n      Axis: Z\r\n      Channel Name: intensity\r\n      Class: rviz_default_plugins/LaserScan\r\n      Color: 255; 255; 255\r\n      Color Transformer: Intensity\r\n      Decay Time: 0\r\n      Enabled: true\r\n      Invert Rainbow: false\r\n      Max Color: 255; 255; 255\r\n      Max Intensity: 0\r\n      Min Color: 0; 0; 0\r\n      Min Intensity: 0\r\n      Name: LaserScan\r\n      Position Transformer: XYZ\r\n      Queue Size: 10\r\n      Selectable: true\r\n      Size (Pixels): 3\r\n      Size (m): 0.009999999776482582\r\n      Style: Flat Squares\r\n      Topic:\r\n        Value: /scan\r\n      Use Fixed Frame: true\r\n      Use rainbow: true\r\n      Value: true\r\n  Enabled: true\r\n  Global Options:\r\n    Background Color: 48; 48; 48\r\n    Fixed Frame: base_link\r\n    Frame Rate: 30\r\n  Name: root\r\n  Tools:\r\n    - Class: rviz_default_plugins/Interact\r\n      Hide Inactive Objects: true\r\n    - Class: rviz_default_plugins/MoveCamera\r\n    - Class: rviz_default_plugins/Select\r\n    - Class: rviz_default_plugins/FocusCamera\r\n    - Class: rviz_default_plugins/2D Goal Pose\r\n      Topic:\r\n        Value: /goal_pose\r\n    - Class: rviz_default_plugins/Publish Point\r\n      Single click: true\r\n      Topic:\r\n        Value: /clicked_point\r\n  Transformation:\r\n    Current:\r\n      Class: rviz_default_plugins/TF\r\n  Value: true\r\n  Views:\r\n    Current:\r\n      Class: rviz_default_plugins/Orbit\r\n      Name: Current View\r\n      Target Frame: base_link\r\n      Value: Orbit (rviz)\r\n      Yaw: 0\r\n      Pitch: 0\r\n      Roll: 0\r\n      Distance: 10\r\n      Focal Point:\r\n        X: 0\r\n        Y: 0\r\n        Z: 0\r\n      Focal Shape Fixed Size: true\r\n      Focal Shape Size: 0.05000000074505806\r\n    Saved: ~\r\nWindow Geometry:\r\n  Displays:\r\n    collapsed: false\r\n  Height: 846\r\n  Hide Left Dock: false\r\n  Hide Right Dock: false\r\n  QMainWindow State: 000000ff00000000fd000000040000000000000156000002f4fc0200000008fb0000001200530065006c0065006300740069006f006e00000001e10000009b0000005c00fffffffb0000001e0054006f006f006c002000500072006f007000650072007400690065007302000001ed000001df00000185000000a3fb000000120056006900650077007300200054006f006f02000001df000002110000018500000122fb000000200054006f006f006c002000500072006f0070006500720074006900650073003203000002880000011d000002210000017afb000000100044006900730070006c006100790073010000003d000002f4000000c900fffffffb0000002000730065006c0065006300740069006f006e00200062007500660066006500720200000138000000aa0000023a00000294fb00000014005700690064006500530074006500720065006f02000000e6000000d2000003ee0000030bfb0000000c004b0069006e0065006300740200000186000001060000030c00000261000000010000010f000002f4fc0200000003fb0000001e0054006f006f006c002000500072006f00700065007200740069006500730100000041000000780000000000000000fb0000000a00560069006500770073000000003d000002f4000000a400fffffffb0000001200530065006c0065006300740069006f006e010000025a000000b200000000000000000000000200000490000000a9fc0100000001fb0000000a00560069006500770073030000004e00000080000002e10000019700000003000004420000003efc0100000002fb0000000800540069006d00650100000000000004420000000000000000fb0000000800540069006d006501000000000000045000000000000000000000023f000002f400000004000000040000000800000008fc0000000100000002000000010000000a0054006f006f006c00730100000000ffffffff0000000000000000\r\n  Width: 1200\r\n  X: 72\r\n  Y: 60\n'})}),"\n",(0,a.jsx)(r.h2,{id:"-hands-on-exercise-complete-the-delivery-robot-system",children:"\ud83e\uddea Hands-On Exercise: Complete the Delivery Robot System"}),"\n",(0,a.jsx)(r.p,{children:"Complete the autonomous delivery robot system with the following requirements:"}),"\n",(0,a.jsxs)(r.p,{children:[(0,a.jsx)(r.strong,{children:"Expected Time:"})," 90 minutes"]}),"\n",(0,a.jsx)(r.p,{children:(0,a.jsx)(r.strong,{children:"Requirements:"})}),"\n",(0,a.jsxs)(r.ul,{children:["\n",(0,a.jsx)(r.li,{children:"Complete all package files and structure"}),"\n",(0,a.jsx)(r.li,{children:"Implement navigation to pickup and delivery locations"}),"\n",(0,a.jsx)(r.li,{children:"Add object detection and avoidance"}),"\n",(0,a.jsx)(r.li,{children:"Create simulation launch file"}),"\n",(0,a.jsx)(r.li,{children:"Test the complete system integration"}),"\n"]}),"\n",(0,a.jsx)(r.p,{children:(0,a.jsx)(r.strong,{children:"Instructions:"})}),"\n",(0,a.jsxs)(r.ol,{children:["\n",(0,a.jsx)(r.li,{children:"Create the complete package structure with all files"}),"\n",(0,a.jsx)(r.li,{children:"Implement the robot controller with navigation capabilities"}),"\n",(0,a.jsx)(r.li,{children:"Add sensor processing for obstacle detection"}),"\n",(0,a.jsx)(r.li,{children:"Create the state machine for delivery operations"}),"\n",(0,a.jsx)(r.li,{children:"Test the system with launch files"}),"\n"]}),"\n",(0,a.jsx)(r.p,{children:(0,a.jsx)(r.strong,{children:"Solution Hints:"})}),"\n",(0,a.jsxs)(r.ul,{children:["\n",(0,a.jsx)(r.li,{children:"Use Nav2 for navigation capabilities"}),"\n",(0,a.jsx)(r.li,{children:"Implement proper error handling and safety measures"}),"\n",(0,a.jsx)(r.li,{children:"Test each component individually before system integration"}),"\n",(0,a.jsx)(r.li,{children:"Use parameters for configuration flexibility"}),"\n"]}),"\n",(0,a.jsx)(r.h2,{id:"-key-takeaways",children:"\ud83d\udca1 Key Takeaways"}),"\n",(0,a.jsxs)(r.ul,{children:["\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"Complete ROS 2 packages"})," integrate all core concepts: nodes, topics, services, actions, parameters, and URDF"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"Modular design"})," with separate nodes for different functions improves maintainability"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"Launch files"})," orchestrate complex systems with proper configuration"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"Parameters"})," enable runtime configuration without code changes"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"State machines"})," are powerful for managing complex robotic behaviors"]}),"\n"]}),"\n",(0,a.jsx)(r.h2,{id:"-further-reading",children:"\ud83d\udcda Further Reading"}),"\n",(0,a.jsxs)(r.ul,{children:["\n",(0,a.jsx)(r.li,{children:(0,a.jsx)(r.a,{href:"https://docs.ros.org/en/rolling/How-To-Guides/Creating-Your-First-ROS2-Package.html",children:"ROS 2 Package Development"})}),"\n",(0,a.jsx)(r.li,{children:(0,a.jsx)(r.a,{href:"https://docs.ros.org/en/rolling/The-ROS2-Project/Contributing/Code-Style-Language-Versions.html",children:"ROS 2 Best Practices"})}),"\n",(0,a.jsx)(r.li,{children:(0,a.jsx)(r.a,{href:"https://navigation.ros.org/",children:"Navigation Stack (Nav2)"})}),"\n"]}),"\n",(0,a.jsx)(r.hr,{}),"\n",(0,a.jsxs)(r.p,{children:[(0,a.jsx)(r.strong,{children:"Module Complete:"})," You've successfully built a complete ROS 2 package that integrates all the concepts from Module 1. Continue to ",(0,a.jsx)(r.a,{href:"/module-2/introduction",children:"Module 2: Gazebo & Unity - Digital Twin"})]})]})}function _(e={}){const{wrapper:r}={...(0,s.R)(),...e.components};return r?(0,a.jsx)(r,{...e,children:(0,a.jsx)(m,{...e})}):m(e)}},7197:(e,r,n)=>{n.d(r,{A:()=>s});var t=n(6540),a=n(4848);function s({chapterContent:e,userBackground:r}){const[n,s]=(0,t.useState)(e),[o,i]=(0,t.useState)(!1),[l,c]=(0,t.useState)(!1),[d,m]=(0,t.useState)(!1);return(0,a.jsxs)("div",{style:{backgroundColor:"#f8f9fa",borderRadius:"12px",padding:"1.5rem",marginBottom:"2rem",border:"2px solid #e0e0e0"},children:[(0,a.jsxs)("div",{style:{display:"flex",flexWrap:"wrap",gap:"0.75rem",marginBottom:"1.5rem"},children:[(0,a.jsxs)("button",{onClick:()=>{m(!0),setTimeout(()=>{const n=r?.experienceLevel||"beginner",t=r?.softwareBackground||"",a=r?.hardwareBackground||"";let o=e;"beginner"===n?o=`\n## \ud83c\udf31 Beginner-Friendly Version\n\n*This content has been tailored for beginners. Take your time and practice each concept!*\n\n---\n\n${e}\n\n---\n\n### \ud83d\udca1 Tips for Beginners:\n- Don't rush through the material\n- Try coding examples yourself\n- Use Google when stuck\n- Join robotics communities for help\n        `:"intermediate"===n?o=`\n## \ud83d\udcc8 Intermediate Track\n\n*You have some experience - this version includes additional challenges!*\n\n---\n\n${e}\n\n---\n\n### \ud83c\udfaf Challenge Yourself:\n- Implement optimizations\n- Try different approaches\n- Build your own variations\n- Share your projects with others\n        `:"advanced"===n&&(o=`\n## \ud83d\ude80 Advanced Deep Dive\n\n*Expert content with cutting-edge concepts and research directions.*\n\n---\n\n${e}\n\n---\n\n### \u26a1 Advanced Topics:\n- Latest research papers\n- Performance optimization techniques\n- Edge cases and error handling\n- Contributing to open source projects\n        `),t.toLowerCase().includes("python")&&(o+="\n\n### \ud83d\udc0d Python Developer Tip:\nYou can leverage your Python skills here! Most robotics frameworks have excellent Python bindings."),(a.toLowerCase().includes("arduino")||a.toLowerCase().includes("raspberry"))&&(o+="\n\n### \ud83d\udd27 Hardware Experience Bonus:\nYour hardware background gives you an advantage! You already understand embedded systems."),s(o),i(!0),m(!1)},500)},disabled:d||o,style:{display:"flex",alignItems:"center",gap:"0.5rem",backgroundColor:o?"#28a745":"#9b59b6",color:"white",padding:"0.75rem 1.25rem",border:"none",borderRadius:"8px",fontSize:"0.95rem",fontWeight:"600",cursor:d||o?"not-allowed":"pointer",opacity:d||o?.6:1,transition:"all 0.3s"},onMouseOver:e=>{d||o||(e.target.style.transform="scale(1.05)")},onMouseOut:e=>{e.target.style.transform="scale(1)"},children:[(0,a.jsx)("span",{children:"\u2728"}),o?"Personalized \u2713":"Personalize Content"]}),(0,a.jsxs)("button",{onClick:()=>{m(!0),setTimeout(()=>{let r=e;Object.entries({Robot:"\u0631\u0648\u0628\u0648\u0679 (Robot)",robot:"\u0631\u0648\u0628\u0648\u0679 (robot)",Sensor:"\u0633\u06cc\u0646\u0633\u0631 (Sensor)",sensor:"\u0633\u06cc\u0646\u0633\u0631 (sensor)",Control:"\u06a9\u0646\u0679\u0631\u0648\u0644 (Control)",control:"\u06a9\u0646\u0679\u0631\u0648\u0644 (control)",Simulation:"\u0646\u0642\u0627\u0644\u06cc (Simulation)",simulation:"\u0646\u0642\u0627\u0644\u06cc (simulation)","Artificial Intelligence":"\u0645\u0635\u0646\u0648\u0639\u06cc \u0630\u06c1\u0627\u0646\u062a (AI)","artificial intelligence":"\u0645\u0635\u0646\u0648\u0639\u06cc \u0630\u06c1\u0627\u0646\u062a (AI)",AI:"\u0627\u06d2 \u0622\u0626\u06cc (AI)","Physical AI":"\u0641\u0632\u06cc\u06a9\u0644 \u0627\u06d2 \u0622\u0626\u06cc (Physical AI)",Humanoid:"\u0627\u0646\u0633\u0627\u0646 \u0646\u0645\u0627 (Humanoid)",humanoid:"\u0627\u0646\u0633\u0627\u0646 \u0646\u0645\u0627 (humanoid)",Introduction:"\u062a\u0639\u0627\u0631\u0641 (Introduction)",Module:"\u0645\u0627\u0688\u06cc\u0648\u0644 (Module)",module:"\u0645\u0627\u0688\u06cc\u0648\u0644 (module)",Chapter:"\u0628\u0627\u0628 (Chapter)",chapter:"\u0628\u0627\u0628 (chapter)",Learning:"\u0633\u06cc\u06a9\u06be\u0646\u0627 (Learning)",learning:"\u0633\u06cc\u06a9\u06be\u0646\u0627 (learning)",Programming:"\u067e\u0631\u0648\u06af\u0631\u0627\u0645\u0646\u06af (Programming)",programming:"\u067e\u0631\u0648\u06af\u0631\u0627\u0645\u0646\u06af (programming)",Code:"\u06a9\u0648\u0688 (Code)",code:"\u06a9\u0648\u0688 (code)",System:"\u0646\u0638\u0627\u0645 (System)",system:"\u0646\u0638\u0627\u0645 (system)",Data:"\u0688\u06cc\u0679\u0627 (Data)",data:"\u0688\u06cc\u0679\u0627 (data)",Algorithm:"\u0627\u0644\u06af\u0648\u0631\u062a\u06be\u0645 (Algorithm)",algorithm:"\u0627\u0644\u06af\u0648\u0631\u062a\u06be\u0645 (algorithm)",Model:"\u0645\u0627\u0688\u0644 (Model)",model:"\u0645\u0627\u0688\u0644 (model)",Training:"\u062a\u0631\u0628\u06cc\u062a (Training)",training:"\u062a\u0631\u0628\u06cc\u062a (training)","Neural Network":"\u0639\u0635\u0628\u06cc \u0646\u06cc\u0679 \u0648\u0631\u06a9 (Neural Network)","Computer Vision":"\u06a9\u0645\u067e\u06cc\u0648\u0679\u0631 \u0648\u0698\u0646 (Computer Vision)","Machine Learning":"\u0645\u0634\u06cc\u0646 \u0644\u0631\u0646\u0646\u06af (Machine Learning)"}).forEach(([e,n])=>{const t=new RegExp(`\\b${e}\\b`,"g");r=r.replace(t,n)}),r=`\n# \ud83c\uddf5\ud83c\uddf0 \u0627\u0631\u062f\u0648 \u062a\u0631\u062c\u0645\u06c1 / Urdu Translation\n\n*\u0646\u0648\u0679: \u06cc\u06c1 \u062e\u0648\u062f\u06a9\u0627\u0631 \u062a\u0631\u062c\u0645\u06c1 \u06c1\u06d2\u06d4 \u062a\u06a9\u0646\u06cc\u06a9\u06cc \u0627\u0635\u0637\u0644\u0627\u062d\u0627\u062a \u0627\u0646\u06af\u0631\u06cc\u0632\u06cc \u0645\u06cc\u06ba \u0628\u06be\u06cc \u0634\u0627\u0645\u0644 \u06c1\u06cc\u06ba\u06d4*\n\n*Note: This is an automatic translation. Technical terms are included in English for clarity.*\n\n---\n\n${r}\n\n---\n\n### \u0627\u0636\u0627\u0641\u06cc \u0645\u0639\u0644\u0648\u0645\u0627\u062a / Additional Info:\n- \u062a\u06a9\u0646\u06cc\u06a9\u06cc \u0627\u0644\u0641\u0627\u0638 \u062f\u0648\u0646\u0648\u06ba \u0632\u0628\u0627\u0646\u0648\u06ba \u0645\u06cc\u06ba \u062f\u06cc\u06d2 \u06af\u0626\u06d2 \u06c1\u06cc\u06ba\n- Technical terms are provided in both languages\n- \u0645\u0632\u06cc\u062f \u0633\u0648\u0627\u0644\u0627\u062a \u06a9\u06d2 \u0644\u06cc\u06d2 \u0627\u0633\u062a\u0627\u062f \u0633\u06d2 \u0631\u0627\u0628\u0637\u06c1 \u06a9\u0631\u06cc\u06ba\n- Contact your instructor for more questions\n      `,s(r),c(!0),m(!1)},500)},disabled:d||l,style:{display:"flex",alignItems:"center",gap:"0.5rem",backgroundColor:l?"#28a745":"#27ae60",color:"white",padding:"0.75rem 1.25rem",border:"none",borderRadius:"8px",fontSize:"0.95rem",fontWeight:"600",cursor:d||l?"not-allowed":"pointer",opacity:d||l?.6:1,transition:"all 0.3s"},onMouseOver:e=>{d||l||(e.target.style.transform="scale(1.05)")},onMouseOut:e=>{e.target.style.transform="scale(1)"},children:[(0,a.jsx)("span",{children:"\ud83c\uddf5\ud83c\uddf0"}),l?"\u0627\u0631\u062f\u0648 \u0645\u06cc\u06ba \u2713":"Translate to Urdu"]}),(o||l)&&(0,a.jsxs)("button",{onClick:()=>{s(e),i(!1),c(!1)},style:{display:"flex",alignItems:"center",gap:"0.5rem",backgroundColor:"#6c757d",color:"white",padding:"0.75rem 1.25rem",border:"none",borderRadius:"8px",fontSize:"0.95rem",fontWeight:"600",cursor:"pointer",transition:"all 0.3s"},onMouseOver:e=>{e.target.style.transform="scale(1.05)"},onMouseOut:e=>{e.target.style.transform="scale(1)"},children:[(0,a.jsx)("span",{children:"\u21ba"}),"Reset to Original"]})]}),(0,a.jsx)("div",{style:{backgroundColor:"white",borderRadius:"8px",padding:"1.5rem",border:"1px solid #dee2e6",minHeight:"200px"},children:d?(0,a.jsx)("div",{style:{display:"flex",alignItems:"center",justifyContent:"center",padding:"3rem"},children:(0,a.jsx)("div",{style:{width:"40px",height:"40px",border:"4px solid #f3f3f3",borderTop:"4px solid #667eea",borderRadius:"50%",animation:"spin 1s linear infinite"}})}):(0,a.jsx)("div",{style:{whiteSpace:"pre-wrap",lineHeight:"1.6",color:"#333"},children:n})}),!d&&(0,a.jsxs)("div",{style:{marginTop:"1rem",display:"flex",flexWrap:"wrap",gap:"0.5rem"},children:[o&&(0,a.jsxs)("span",{style:{backgroundColor:"#e7d4f7",color:"#6f42c1",padding:"0.4rem 0.8rem",borderRadius:"20px",fontSize:"0.85rem",fontWeight:"600"},children:["\ud83c\udfaf Tailored to ",r?.experienceLevel||"your"," level"]}),l&&(0,a.jsx)("span",{style:{backgroundColor:"#d4edda",color:"#155724",padding:"0.4rem 0.8rem",borderRadius:"20px",fontSize:"0.85rem",fontWeight:"600"},children:"\ud83c\uddf5\ud83c\uddf0 \u0627\u0631\u062f\u0648 Translation Active"})]}),(0,a.jsx)("style",{children:"\n        @keyframes spin {\n          0% { transform: rotate(0deg); }\n          100% { transform: rotate(360deg); }\n        }\n      "})]})}},8453:(e,r,n)=>{n.d(r,{R:()=>o,x:()=>i});var t=n(6540);const a={},s=t.createContext(a);function o(e){const r=t.useContext(s);return t.useMemo(function(){return"function"==typeof e?e(r):{...r,...e}},[r,e])}function i(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),t.createElement(s.Provider,{value:r},e.children)}}}]);