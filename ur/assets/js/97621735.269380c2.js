"use strict";(globalThis.webpackChunkmy_book=globalThis.webpackChunkmy_book||[]).push([[2675],{6202:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>u,frontMatter:()=>a,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"module-1/introduction","title":"ROS 2 - The Robotic Nervous System","description":"<ChapterControls","source":"@site/docs/module-1/introduction.mdx","sourceDirName":"module-1","slug":"/module-1/introduction","permalink":"/https://github.com/Muhammad-Nawaz453/Physical-AI---Humanoid-Robotics-BOOK/ur/module-1/introduction","draft":false,"unlisted":false,"editUrl":"https://github.com/Muhammad-Nawaz453/Physical-AI---Humanoid-Robotics/tree/main/docs/module-1/introduction.mdx","tags":[],"version":"current","frontMatter":{"title":"ROS 2 - The Robotic Nervous System"},"sidebar":"tutorialSidebar","previous":{"title":"Software Setup: Preparing Your Physical AI Workspace \ud83d\udee0\ufe0f\ud83d\udda5\ufe0f","permalink":"/https://github.com/Muhammad-Nawaz453/Physical-AI---Humanoid-Robotics-BOOK/ur/getting-started/software-setup"},"next":{"title":"ROS 2 Architecture: The Blueprint of a Robotic Mind \ud83c\udfd7\ufe0f\ud83c\udf10","permalink":"/https://github.com/Muhammad-Nawaz453/Physical-AI---Humanoid-Robotics-BOOK/ur/module-1/ros2-architecture"}}');var r=s(4848),t=s(8453),o=s(7197);const a={title:"ROS 2 - The Robotic Nervous System"},l="Module 1: ROS 2 - The Robotic Nervous System \ud83e\udd16",c={},d=[{value:"Introduction: Unveiling ROS 2 for Physical AI",id:"introduction-unveiling-ros-2-for-physical-ai",level:2},{value:"Learning Objectives \ud83c\udfaf",id:"learning-objectives-",level:3},{value:"What is ROS 2? More Than Just an Operating System \ud83e\udde0",id:"what-is-ros-2-more-than-just-an-operating-system-",level:2},{value:"The Evolution: From ROS 1 to ROS 2 \ud83d\ude80",id:"the-evolution-from-ros-1-to-ros-2-",level:3},{value:"Why ROS 2 Matters for Physical AI \ud83e\udd16 + \ud83e\udde0 = \u2728",id:"why-ros-2-matters-for-physical-ai-----",level:2},{value:"ROS 2 Core Concepts: Building Blocks of a Robotic Brain \ud83c\udfd7\ufe0f",id:"ros-2-core-concepts-building-blocks-of-a-robotic-brain-\ufe0f",level:2},{value:"1. Nodes: The Brain Cells \ud83e\udde0",id:"1-nodes-the-brain-cells-",level:3},{value:"2. Topics: The Sensory Nerves and Motor Commands \ud83d\udce1",id:"2-topics-the-sensory-nerves-and-motor-commands-",level:3},{value:"3. Services: The Reflex Arcs (Request/Response) \ud83e\udd1d",id:"3-services-the-reflex-arcs-requestresponse-",level:3},{value:"4. Actions: The Complex Behaviors (Long-Running Tasks) \ud83c\udfc3\u200d\u2642\ufe0f",id:"4-actions-the-complex-behaviors-long-running-tasks-\ufe0f",level:3},{value:"5. Parameters: The Configuration Settings \u2699\ufe0f",id:"5-parameters-the-configuration-settings-\ufe0f",level:3},{value:"A Simple ROS 2 Example: &quot;Hello Robot!&quot; \ud83d\udc4b",id:"a-simple-ros-2-example-hello-robot-",level:2},{value:"Prerequisites",id:"prerequisites",level:3},{value:"1. Create a ROS 2 Workspace and Package",id:"1-create-a-ros-2-workspace-and-package",level:3},{value:"2. <code>talker</code> Node (Python)",id:"2-talker-node-python",level:3},{value:"3. <code>listener</code> Node (Python)",id:"3-listener-node-python",level:3},{value:"4. Update <code>setup.py</code>",id:"4-update-setuppy",level:3},{value:"5. Build and Run",id:"5-build-and-run",level:3},{value:"Conclusion: ROS 2 as the Backbone for Intelligent Robots \ud83c\udf1f",id:"conclusion-ros-2-as-the-backbone-for-intelligent-robots-",level:2}];function h(e){const n={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(o.A,{chapterContent:"\n  # Your chapter content here\n  \n  This is the text that will be personalized and translated.\n",userBackground:"undefined"!=typeof window?JSON.parse(localStorage.getItem("user")||"{}"):{}}),"\n",(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"module-1-ros-2---the-robotic-nervous-system-",children:"Module 1: ROS 2 - The Robotic Nervous System \ud83e\udd16"})}),"\n",(0,r.jsx)(n.h2,{id:"introduction-unveiling-ros-2-for-physical-ai",children:"Introduction: Unveiling ROS 2 for Physical AI"}),"\n",(0,r.jsx)(n.p,{children:'Welcome to the exciting world where robotics meets artificial intelligence! In this module, we embark on a journey to understand and master ROS 2 (Robot Operating System 2), a foundational framework that acts as the "nervous system" for intelligent robots. As we delve into Physical AI, where algorithms interact with the tangible world, ROS 2 becomes an indispensable tool for bridging the gap between high-level AI decision-making and low-level hardware control.'}),"\n",(0,r.jsx)(n.p,{children:'Imagine building a complex organism. It needs a way for its brain to communicate with its limbs, eyes, and ears. In robotics, especially with the advent of sophisticated AI, this communication challenge is amplified. Robots are intricate systems comprising sensors (eyes and ears), actuators (limbs), and a "brain" (onboard computers running AI algorithms). How do these disparate components talk to each other efficiently, reliably, and in real-time? Enter ROS 2.'}),"\n",(0,r.jsx)(n.p,{children:"This chapter will lay the groundwork for understanding what ROS 2 is, why it's crucial for the development of modern Physical AI systems, and how its architectural design empowers developers to build robust, scalable, and distributed robotic applications. Get ready to explore the core concepts that make ROS 2 a game-changer in robotics!"}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h3,{id:"learning-objectives-",children:"Learning Objectives \ud83c\udfaf"}),"\n",(0,r.jsx)(n.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Define"})," what ROS 2 is and articulate its primary purpose in robotics."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Explain"})," the historical context and improvements of ROS 2 over its predecessor, ROS 1."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Identify"})," the key reasons why ROS 2 is essential for building Physical AI applications."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Understand"})," the fundamental architectural components of ROS 2, including nodes, topics, services, actions, and parameters."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Illustrate"})," the communication patterns within a ROS 2 system through practical examples."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Recognize"})," the benefits of ROS 2's distributed and real-time capabilities."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Set up"}),' a basic ROS 2 environment and run a simple "Hello World" example.']}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"what-is-ros-2-more-than-just-an-operating-system-",children:"What is ROS 2? More Than Just an Operating System \ud83e\udde0"}),"\n",(0,r.jsxs)(n.p,{children:["Despite its name, ROS 2 is not an operating system like Linux or Windows. Instead, it's a ",(0,r.jsx)(n.strong,{children:"meta-operating system"})," for robots. Think of it as a set of software libraries, tools, and conventions designed to simplify the task of building complex robot applications. It provides a standardized way for different software components of a robot to communicate and work together."]}),"\n",(0,r.jsx)(n.p,{children:"At its core, ROS 2 facilitates:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Inter-process Communication:"})," It enables various independent programs (called ",(0,r.jsx)(n.em,{children:"nodes"}),") to exchange data. This could be anything from sensor readings (camera images, lidar scans) to motor commands, navigation goals, or AI inferences."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Hardware Abstraction:"})," It offers a layer of abstraction that allows developers to write code independent of specific hardware. This means the same navigation algorithm could potentially run on different robots with varying motor controllers and sensor setups, given appropriate ROS 2 drivers."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Code Reusability:"})," ROS 2 promotes a modular design where components can be developed and tested independently, then integrated into larger systems. This fosters a vibrant community contribution model, leading to a rich ecosystem of reusable packages for common robotic functionalities."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Tools and Utilities:"})," It comes with a suite of powerful tools for visualization (Rviz), debugging (rqt_console), data logging (rosbag), and package management."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"the-evolution-from-ros-1-to-ros-2-",children:"The Evolution: From ROS 1 to ROS 2 \ud83d\ude80"}),"\n",(0,r.jsx)(n.p,{children:"ROS 1, released in 2007, revolutionized robotics by providing an open-source framework that rapidly accelerated research and development. However, it had limitations, particularly concerning:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Real-time Capabilities:"})," ROS 1 was not designed with hard real-time requirements in mind, making it challenging for applications needing precise timing (e.g., industrial control)."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Distributed Systems:"})," While it could be distributed, its underlying communication layer (TCPROS) was less robust for multi-robot systems or unreliable networks."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Security:"})," ROS 1 lacked built-in security features, which is a major concern for commercial and critical applications."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Windows/macOS Support:"})," Primarily Linux-centric."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"ROS 2 was reimagined from the ground up to address these challenges, bringing significant improvements:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"DDS (Data Distribution Service) as the Middleware:"})," This is the most crucial change. DDS is an industry standard for real-time, high-performance, and scalable data-centric communication. It provides quality-of-service (QoS) policies for reliability, latency, durability, and security, making ROS 2 suitable for a wider range of applications, including industrial robotics and autonomous vehicles."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Improved Real-time Performance:"})," DDS enables better control over communication timing, which is vital for applications requiring deterministic behavior."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Enhanced Security:"})," Leveraging DDS, ROS 2 incorporates security features like authentication, encryption, and access control out-of-the-box."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Multi-platform Support:"})," ROS 2 officially supports Linux, Windows, and macOS, expanding its reach to more development environments."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Lifecycle Management:"})," Nodes in ROS 2 can have defined lifecycle states (e.g., ",(0,r.jsx)(n.code,{children:"unconfigured"}),", ",(0,r.jsx)(n.code,{children:"inactive"}),", ",(0,r.jsx)(n.code,{children:"active"}),"), allowing for more robust and predictable system startup and shutdown."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Better Multi-robot Support:"})," The DDS middleware inherently handles discovery and communication across multiple machines and networks more gracefully."]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"why-ros-2-matters-for-physical-ai-----",children:"Why ROS 2 Matters for Physical AI \ud83e\udd16 + \ud83e\udde0 = \u2728"}),"\n",(0,r.jsx)(n.p,{children:"Physical AI is all about intelligent agents operating in the real world. This involves complex interactions between perception (vision, lidar), cognition (decision-making, planning, learning), and action (motor control, manipulation). ROS 2 provides the perfect infrastructure for stitching these elements together."}),"\n",(0,r.jsx)(n.p,{children:"Here\u2019s why ROS 2 is indispensable for Physical AI:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Integration of Diverse AI Modules:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"A Physical AI robot might use a neural network for object detection, a separate module for path planning, and another for natural language understanding. ROS 2 allows these diverse AI algorithms, often written in different programming languages (Python, C++), to seamlessly exchange data."}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Example:"}),' A camera node publishes raw image data, an AI vision node subscribes to it, processes it (e.g., detects a "cup"), and publishes a "cup detected" message. A manipulation node then subscribes to this message to plan a grasping action.']}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Real-time Responsiveness and Determinism:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"In Physical AI, delayed responses can have severe consequences (e.g., a self-driving car not reacting in time). ROS 2's focus on real-time communication, backed by DDS, ensures that critical sensor data reaches AI decision-makers and actuator commands reach motors with predictable latency."}),"\n",(0,r.jsx)(n.li,{children:"This is crucial for tasks like real-time obstacle avoidance, precise robotic arm movements, and dynamic human-robot interaction."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Distributed Computing for Edge AI and Cloud AI:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Modern AI often involves heavy computation. Some AI models might run on powerful onboard GPUs (edge AI), while others might offload processing to cloud servers (cloud AI). ROS 2\u2019s distributed nature allows nodes to run on different machines \u2013 embedded systems, workstations, or even cloud instances \u2013 and communicate efficiently."}),"\n",(0,r.jsx)(n.li,{children:"This flexibility is vital for scaling Physical AI applications and leveraging the best computing resources for different parts of the AI pipeline."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Hardware Agnosticism and Sensor Fusion:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Physical AI robots typically integrate multiple types of sensors (cameras, lidar, IMUs, force sensors) to build a comprehensive understanding of their environment (sensor fusion). ROS 2 provides standardized interfaces for these sensors, making it easier to integrate new hardware and combine data streams."}),"\n",(0,r.jsx)(n.li,{children:"The AI algorithms can then consume these fused data streams without needing to worry about the low-level details of each sensor."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Robustness and Fault Tolerance:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Robots operating in the real world must be robust. ROS 2's lifecycle management allows for controlled startup and shutdown of nodes, and DDS's QoS policies enable reliable message delivery, even in the presence of network glitches or node failures."}),"\n",(0,r.jsx)(n.li,{children:"This contributes to building more resilient Physical AI systems that can recover from errors or gracefully degrade performance."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Security for Critical Applications:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"As Physical AI moves into sensitive domains like healthcare, logistics, and defense, security becomes paramount. ROS 2's built-in security features protect against unauthorized access, tampering, and denial-of-service attacks, ensuring the integrity and safety of intelligent robots."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"ros-2-core-concepts-building-blocks-of-a-robotic-brain-\ufe0f",children:"ROS 2 Core Concepts: Building Blocks of a Robotic Brain \ud83c\udfd7\ufe0f"}),"\n",(0,r.jsx)(n.p,{children:"To understand how ROS 2 functions as a nervous system, let's explore its fundamental concepts:"}),"\n",(0,r.jsx)(n.h3,{id:"1-nodes-the-brain-cells-",children:"1. Nodes: The Brain Cells \ud83e\udde0"}),"\n",(0,r.jsxs)(n.p,{children:["A ",(0,r.jsx)(n.strong,{children:"node"})," is an executable process that performs a specific computation. In ROS 2, every functional unit of a robot's software is typically encapsulated within a node. This promotes modularity and makes it easy to replace or upgrade individual components."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Examples:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"A camera driver node that acquires images."}),"\n",(0,r.jsx)(n.li,{children:"An object detection node that processes images."}),"\n",(0,r.jsx)(n.li,{children:"A motor control node that sends commands to motors."}),"\n",(0,r.jsx)(n.li,{children:"A navigation node that plans paths."}),"\n",(0,r.jsx)(n.li,{children:"A user interface node."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"2-topics-the-sensory-nerves-and-motor-commands-",children:"2. Topics: The Sensory Nerves and Motor Commands \ud83d\udce1"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Topics"})," are named buses over which nodes exchange messages asynchronously. It's a publish/subscribe communication model:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"A node that wants to send data publishes messages to a specific topic."}),"\n",(0,r.jsx)(n.li,{children:"A node that wants to receive data subscribes to that topic."}),"\n",(0,r.jsx)(n.li,{children:"Many publishers can send messages to the same topic, and many subscribers can receive messages from the same topic."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Topics are ideal for streaming data, where the latest information is always the most important (e.g., sensor readings, continuous motor commands)."}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Message Types:"})," Each topic has a defined ",(0,r.jsx)(n.em,{children:"message type"})," (e.g., ",(0,r.jsx)(n.code,{children:"sensor_msgs/msg/Image"})," for camera images, ",(0,r.jsx)(n.code,{children:"std_msgs/msg/String"})," for simple text). This ensures that data exchanged is structured and understood by all participating nodes."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"3-services-the-reflex-arcs-requestresponse-",children:"3. Services: The Reflex Arcs (Request/Response) \ud83e\udd1d"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Services"})," provide a synchronous request/response communication mechanism between nodes. Unlike topics, where data flows continuously, services are used when a node needs to request a specific computation or piece of information from another node and wait for a response."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Examples:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:'A mapping node requesting a "start mapping" command from a localization node.'}),"\n",(0,r.jsx)(n.li,{children:"A UI node requesting the robot's current battery status."}),"\n",(0,r.jsx)(n.li,{children:'An AI planning node asking a perception node to "identify objects in region X."'}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Service Types:"})," Like topics, services have ",(0,r.jsx)(n.em,{children:"service types"})," that define the structure of the request and response messages."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"4-actions-the-complex-behaviors-long-running-tasks-\ufe0f",children:"4. Actions: The Complex Behaviors (Long-Running Tasks) \ud83c\udfc3\u200d\u2642\ufe0f"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Actions"})," are a higher-level communication mechanism used for long-running, goal-oriented tasks that might involve preemption (canceling a task) and continuous feedback. They combine aspects of topics and services."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"When a node requests an action, it sends a goal."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"The action server provides continuous feedback on the progress of the goal."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"The requesting node can cancel the goal at any time."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"When the action is complete, the server sends a final result."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Examples:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:'A navigation node instructing the robot to "go to coordinates (X, Y)" (feedback: current position, result: reached goal, preempt: stop navigating).'}),"\n",(0,r.jsx)(n.li,{children:'A manipulation node instructing a robot arm to "pick up the red block" (feedback: arm position, gripper status, result: block picked, preempt: drop block).'}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Action Types:"})," Actions have ",(0,r.jsx)(n.em,{children:"action types"})," that define the structure for goals, feedback, and results."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"5-parameters-the-configuration-settings-\ufe0f",children:"5. Parameters: The Configuration Settings \u2699\ufe0f"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Parameters"})," allow nodes to expose configuration values that can be changed at runtime or configured at startup. This provides flexibility without recompiling code."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Examples:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Setting the camera's frame rate."}),"\n",(0,r.jsx)(n.li,{children:"Adjusting the proportional gain of a motor controller."}),"\n",(0,r.jsx)(n.li,{children:"Changing a navigation algorithm's maximum speed."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"a-simple-ros-2-example-hello-robot-",children:'A Simple ROS 2 Example: "Hello Robot!" \ud83d\udc4b'}),"\n",(0,r.jsxs)(n.p,{children:["Let's illustrate these concepts with a basic \"Hello Robot!\" example. We'll have two nodes: a ",(0,r.jsx)(n.code,{children:"talker"}),' that publishes "Hello Robot!" messages and a ',(0,r.jsx)(n.code,{children:"listener"})," that receives and prints them."]}),"\n",(0,r.jsx)(n.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,r.jsx)(n.p,{children:"First, ensure you have a ROS 2 environment set up. If not, you can install it following the official documentation (e.g., Foxy Fitzroy, Humble Hawksbill)."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Example for Ubuntu 20.04 (Foxy) or Ubuntu 22.04 (Humble)\r\n# Replace 'foxy' with 'humble' if using Humble Hawksbill\r\n\r\n# Source your ROS 2 environment (adjust path if needed)\r\nsource /opt/ros/foxy/setup.bash\r\n# or for Humble\r\nsource /opt/ros/humble/setup.bash\n"})}),"\n",(0,r.jsx)(n.h3,{id:"1-create-a-ros-2-workspace-and-package",children:"1. Create a ROS 2 Workspace and Package"}),"\n",(0,r.jsx)(n.p,{children:"A workspace is a directory for ROS 2 package development."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"mkdir -p ~/ros2_ws/src\r\ncd ~/ros2_ws/src\r\nros2 pkg create --build-type ament_python my_robot_talker_listener\r\ncd my_robot_talker_listener\n"})}),"\n",(0,r.jsxs)(n.h3,{id:"2-talker-node-python",children:["2. ",(0,r.jsx)(n.code,{children:"talker"})," Node (Python)"]}),"\n",(0,r.jsxs)(n.p,{children:["Create ",(0,r.jsx)(n.code,{children:"my_robot_talker_listener/my_robot_talker_listener/talker.py"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import rclpy\r\nfrom rclpy.node import Node\r\nfrom std_msgs.msg import String\r\n\r\nclass Talker(Node):\r\n    def __init__(self):\r\n        super().__init__('talker') # Initialize the node with the name 'talker'\r\n        self.publisher_ = self.create_publisher(String, 'chatter', 10) # Create a publisher for 'chatter' topic with String message type\r\n        self.i = 0\r\n        timer_period = 0.5  # seconds\r\n        self.timer = self.create_timer(timer_period, self.timer_callback) # Create a timer that calls timer_callback every 0.5 seconds\r\n        self.get_logger().info('Talker node initialized and publishing messages.')\r\n\r\n    def timer_callback(self):\r\n        msg = String()\r\n        msg.data = f'Hello Robot! {self.i}' # Create a message\r\n        self.publisher_.publish(msg) # Publish the message\r\n        self.get_logger().info(f'Publishing: \"{msg.data}\"') # Log the published message\r\n        self.i += 1\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args) # Initialize ROS 2 communication\r\n    talker = Talker() # Create an instance of the Talker node\r\n    rclpy.spin(talker) # Keep the node alive until it's shut down\r\n    talker.destroy_node() # Clean up when done\r\n    rclpy.shutdown() # Shut down ROS 2 communication\r\n\r\nif __name__ == '__main__':\r\n    main()\n"})}),"\n",(0,r.jsxs)(n.h3,{id:"3-listener-node-python",children:["3. ",(0,r.jsx)(n.code,{children:"listener"})," Node (Python)"]}),"\n",(0,r.jsxs)(n.p,{children:["Create ",(0,r.jsx)(n.code,{children:"my_robot_talker_listener/my_robot_talker_listener/listener.py"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import rclpy\r\nfrom rclpy.node import Node\r\nfrom std_msgs.msg import String\r\n\r\nclass Listener(Node):\r\n    def __init__(self):\r\n        super().__init__('listener') # Initialize the node with the name 'listener'\r\n        # Create a subscriber for 'chatter' topic with String message type\r\n        # The callback function self.listener_callback will be called whenever a message is received\r\n        self.subscription = self.create_subscription(\r\n            String,\r\n            'chatter',\r\n            self.listener_callback,\r\n            10)\r\n        self.subscription  # prevent unused variable warning\r\n        self.get_logger().info('Listener node initialized and subscribing to messages.')\r\n\r\n    def listener_callback(self, msg):\r\n        self.get_logger().info(f'I heard: \"{msg.data}\"') # Log the received message\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args) # Initialize ROS 2 communication\r\n    listener = Listener() # Create an instance of the Listener node\r\n    rclpy.spin(listener) # Keep the node alive until it's shut down\r\n    listener.destroy_node() # Clean up when done\r\n    rclpy.shutdown() # Shut down ROS 2 communication\r\n\r\nif __name__ == '__main__':\r\n    main()\n"})}),"\n",(0,r.jsxs)(n.h3,{id:"4-update-setuppy",children:["4. Update ",(0,r.jsx)(n.code,{children:"setup.py"})]}),"\n",(0,r.jsxs)(n.p,{children:["Modify ",(0,r.jsx)(n.code,{children:"my_robot_talker_listener/setup.py"})," to include the entry points for your executables:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from setuptools import find_packages, setup\r\n\r\npackage_name = 'my_robot_talker_listener'\r\n\r\nsetup(\r\n    name=package_name,\r\n    version='0.0.0',\r\n    packages=find_packages(exclude=['test']),\r\n    data_files=[\r\n        ('share/' + package_name, ['package.xml']),\r\n        ('share/ament_index/resource_index/packages', ['resource/' + package_name]),\r\n    ],\r\n    install_requires=['setuptools'],\r\n    zip_safe=True,\r\n    maintainer='Your Name', # Replace with your name\r\n    maintainer_email='your.email@example.com', # Replace with your email\r\n    description='A simple ROS 2 talker-listener example package',\r\n    license='Apache-2.0', # Or your preferred license\r\n    tests_require=['pytest'],\r\n    entry_points={\r\n        'console_scripts': [\r\n            'talker = my_robot_talker_listener.talker:main',\r\n            'listener = my_robot_talker_listener.listener:main',\r\n        ],\r\n    },\r\n)\n"})}),"\n",(0,r.jsx)(n.h3,{id:"5-build-and-run",children:"5. Build and Run"}),"\n",(0,r.jsxs)(n.p,{children:["Navigate back to your workspace root (",(0,r.jsx)(n.code,{children:"~/ros2_ws"}),") and build the package:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"cd ~/ros2_ws\r\ncolcon build --packages-select my_robot_talker_listener\n"})}),"\n",(0,r.jsx)(n.p,{children:"Source your workspace setup files (this makes your new executables available):"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"source install/setup.bash\n"})}),"\n",(0,r.jsx)(n.p,{children:"Now, open two separate terminal windows."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Terminal 1 (Talker):"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"source ~/ros2_ws/install/setup.bash\r\nros2 run my_robot_talker_listener talker\n"})}),"\n",(0,r.jsxs)(n.p,{children:["You should see the ",(0,r.jsx)(n.code,{children:"talker"})," node publishing messages:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'[INFO] [1678886400.123456789] [talker]: Talker node initialized and publishing messages.\r\n[INFO] [1678886400.623456789] [talker]: Publishing: "Hello Robot! 0"\r\n[INFO] [1678886401.123456789] [talker]: Publishing: "Hello Robot! 1"\r\n...\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Terminal 2 (Listener):"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"source ~/ros2_ws/install/setup.bash\r\nros2 run my_robot_talker_listener listener\n"})}),"\n",(0,r.jsxs)(n.p,{children:["You should see the ",(0,r.jsx)(n.code,{children:"listener"})," node receiving and printing messages:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'[INFO] [1678886400.700000000] [listener]: Listener node initialized and subscribing to messages.\r\n[INFO] [1678886400.700000000] [listener]: I heard: "Hello Robot! 0"\r\n[INFO] [1678886401.200000000] [listener]: I heard: "Hello Robot! 1"\r\n...\n'})}),"\n",(0,r.jsx)(n.p,{children:"Congratulations! You've just built and run your first ROS 2 application, demonstrating basic topic-based communication. This simple example forms the basis for much more complex robotic interactions."}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"conclusion-ros-2-as-the-backbone-for-intelligent-robots-",children:"Conclusion: ROS 2 as the Backbone for Intelligent Robots \ud83c\udf1f"}),"\n",(0,r.jsx)(n.p,{children:"In this introductory chapter, we've explored ROS 2, not just as a software framework, but as the essential nervous system for Physical AI. We've seen how its robust communication patterns, real-time capabilities, distributed nature, and security features make it the ideal platform for integrating the diverse and demanding components of intelligent robots."}),"\n",(0,r.jsx)(n.p,{children:"From its evolution beyond ROS 1 to its core concepts of nodes, topics, services, actions, and parameters, ROS 2 provides the architectural blueprint for turning complex hardware and sophisticated AI algorithms into coherent, functional robotic systems. As you proceed through this textbook, you'll continuously build upon these foundations, creating increasingly intelligent and autonomous agents that can truly interact with and understand their physical environments."}),"\n",(0,r.jsx)(n.p,{children:"Get ready to dive deeper into each of these concepts, write more advanced ROS 2 code, and unleash the full potential of Physical AI! The journey has just begun. \ud83d\ude80"})]})}function u(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(h,{...e})}):h(e)}},7197:(e,n,s)=>{s.d(n,{A:()=>t});var i=s(6540),r=s(4848);function t({chapterContent:e,userBackground:n}){const[s,t]=(0,i.useState)(e),[o,a]=(0,i.useState)(!1),[l,c]=(0,i.useState)(!1),[d,h]=(0,i.useState)(!1);return(0,r.jsxs)("div",{style:{backgroundColor:"#f8f9fa",borderRadius:"12px",padding:"1.5rem",marginBottom:"2rem",border:"2px solid #e0e0e0"},children:[(0,r.jsxs)("div",{style:{display:"flex",flexWrap:"wrap",gap:"0.75rem",marginBottom:"1.5rem"},children:[(0,r.jsxs)("button",{onClick:()=>{h(!0),setTimeout(()=>{const s=n?.experienceLevel||"beginner",i=n?.softwareBackground||"",r=n?.hardwareBackground||"";let o=e;"beginner"===s?o=`\n## \ud83c\udf31 Beginner-Friendly Version\n\n*This content has been tailored for beginners. Take your time and practice each concept!*\n\n---\n\n${e}\n\n---\n\n### \ud83d\udca1 Tips for Beginners:\n- Don't rush through the material\n- Try coding examples yourself\n- Use Google when stuck\n- Join robotics communities for help\n        `:"intermediate"===s?o=`\n## \ud83d\udcc8 Intermediate Track\n\n*You have some experience - this version includes additional challenges!*\n\n---\n\n${e}\n\n---\n\n### \ud83c\udfaf Challenge Yourself:\n- Implement optimizations\n- Try different approaches\n- Build your own variations\n- Share your projects with others\n        `:"advanced"===s&&(o=`\n## \ud83d\ude80 Advanced Deep Dive\n\n*Expert content with cutting-edge concepts and research directions.*\n\n---\n\n${e}\n\n---\n\n### \u26a1 Advanced Topics:\n- Latest research papers\n- Performance optimization techniques\n- Edge cases and error handling\n- Contributing to open source projects\n        `),i.toLowerCase().includes("python")&&(o+="\n\n### \ud83d\udc0d Python Developer Tip:\nYou can leverage your Python skills here! Most robotics frameworks have excellent Python bindings."),(r.toLowerCase().includes("arduino")||r.toLowerCase().includes("raspberry"))&&(o+="\n\n### \ud83d\udd27 Hardware Experience Bonus:\nYour hardware background gives you an advantage! You already understand embedded systems."),t(o),a(!0),h(!1)},500)},disabled:d||o,style:{display:"flex",alignItems:"center",gap:"0.5rem",backgroundColor:o?"#28a745":"#9b59b6",color:"white",padding:"0.75rem 1.25rem",border:"none",borderRadius:"8px",fontSize:"0.95rem",fontWeight:"600",cursor:d||o?"not-allowed":"pointer",opacity:d||o?.6:1,transition:"all 0.3s"},onMouseOver:e=>{d||o||(e.target.style.transform="scale(1.05)")},onMouseOut:e=>{e.target.style.transform="scale(1)"},children:[(0,r.jsx)("span",{children:"\u2728"}),o?"Personalized \u2713":"Personalize Content"]}),(0,r.jsxs)("button",{onClick:()=>{h(!0),setTimeout(()=>{let n=e;Object.entries({Robot:"\u0631\u0648\u0628\u0648\u0679 (Robot)",robot:"\u0631\u0648\u0628\u0648\u0679 (robot)",Sensor:"\u0633\u06cc\u0646\u0633\u0631 (Sensor)",sensor:"\u0633\u06cc\u0646\u0633\u0631 (sensor)",Control:"\u06a9\u0646\u0679\u0631\u0648\u0644 (Control)",control:"\u06a9\u0646\u0679\u0631\u0648\u0644 (control)",Simulation:"\u0646\u0642\u0627\u0644\u06cc (Simulation)",simulation:"\u0646\u0642\u0627\u0644\u06cc (simulation)","Artificial Intelligence":"\u0645\u0635\u0646\u0648\u0639\u06cc \u0630\u06c1\u0627\u0646\u062a (AI)","artificial intelligence":"\u0645\u0635\u0646\u0648\u0639\u06cc \u0630\u06c1\u0627\u0646\u062a (AI)",AI:"\u0627\u06d2 \u0622\u0626\u06cc (AI)","Physical AI":"\u0641\u0632\u06cc\u06a9\u0644 \u0627\u06d2 \u0622\u0626\u06cc (Physical AI)",Humanoid:"\u0627\u0646\u0633\u0627\u0646 \u0646\u0645\u0627 (Humanoid)",humanoid:"\u0627\u0646\u0633\u0627\u0646 \u0646\u0645\u0627 (humanoid)",Introduction:"\u062a\u0639\u0627\u0631\u0641 (Introduction)",Module:"\u0645\u0627\u0688\u06cc\u0648\u0644 (Module)",module:"\u0645\u0627\u0688\u06cc\u0648\u0644 (module)",Chapter:"\u0628\u0627\u0628 (Chapter)",chapter:"\u0628\u0627\u0628 (chapter)",Learning:"\u0633\u06cc\u06a9\u06be\u0646\u0627 (Learning)",learning:"\u0633\u06cc\u06a9\u06be\u0646\u0627 (learning)",Programming:"\u067e\u0631\u0648\u06af\u0631\u0627\u0645\u0646\u06af (Programming)",programming:"\u067e\u0631\u0648\u06af\u0631\u0627\u0645\u0646\u06af (programming)",Code:"\u06a9\u0648\u0688 (Code)",code:"\u06a9\u0648\u0688 (code)",System:"\u0646\u0638\u0627\u0645 (System)",system:"\u0646\u0638\u0627\u0645 (system)",Data:"\u0688\u06cc\u0679\u0627 (Data)",data:"\u0688\u06cc\u0679\u0627 (data)",Algorithm:"\u0627\u0644\u06af\u0648\u0631\u062a\u06be\u0645 (Algorithm)",algorithm:"\u0627\u0644\u06af\u0648\u0631\u062a\u06be\u0645 (algorithm)",Model:"\u0645\u0627\u0688\u0644 (Model)",model:"\u0645\u0627\u0688\u0644 (model)",Training:"\u062a\u0631\u0628\u06cc\u062a (Training)",training:"\u062a\u0631\u0628\u06cc\u062a (training)","Neural Network":"\u0639\u0635\u0628\u06cc \u0646\u06cc\u0679 \u0648\u0631\u06a9 (Neural Network)","Computer Vision":"\u06a9\u0645\u067e\u06cc\u0648\u0679\u0631 \u0648\u0698\u0646 (Computer Vision)","Machine Learning":"\u0645\u0634\u06cc\u0646 \u0644\u0631\u0646\u0646\u06af (Machine Learning)"}).forEach(([e,s])=>{const i=new RegExp(`\\b${e}\\b`,"g");n=n.replace(i,s)}),n=`\n# \ud83c\uddf5\ud83c\uddf0 \u0627\u0631\u062f\u0648 \u062a\u0631\u062c\u0645\u06c1 / Urdu Translation\n\n*\u0646\u0648\u0679: \u06cc\u06c1 \u062e\u0648\u062f\u06a9\u0627\u0631 \u062a\u0631\u062c\u0645\u06c1 \u06c1\u06d2\u06d4 \u062a\u06a9\u0646\u06cc\u06a9\u06cc \u0627\u0635\u0637\u0644\u0627\u062d\u0627\u062a \u0627\u0646\u06af\u0631\u06cc\u0632\u06cc \u0645\u06cc\u06ba \u0628\u06be\u06cc \u0634\u0627\u0645\u0644 \u06c1\u06cc\u06ba\u06d4*\n\n*Note: This is an automatic translation. Technical terms are included in English for clarity.*\n\n---\n\n${n}\n\n---\n\n### \u0627\u0636\u0627\u0641\u06cc \u0645\u0639\u0644\u0648\u0645\u0627\u062a / Additional Info:\n- \u062a\u06a9\u0646\u06cc\u06a9\u06cc \u0627\u0644\u0641\u0627\u0638 \u062f\u0648\u0646\u0648\u06ba \u0632\u0628\u0627\u0646\u0648\u06ba \u0645\u06cc\u06ba \u062f\u06cc\u06d2 \u06af\u0626\u06d2 \u06c1\u06cc\u06ba\n- Technical terms are provided in both languages\n- \u0645\u0632\u06cc\u062f \u0633\u0648\u0627\u0644\u0627\u062a \u06a9\u06d2 \u0644\u06cc\u06d2 \u0627\u0633\u062a\u0627\u062f \u0633\u06d2 \u0631\u0627\u0628\u0637\u06c1 \u06a9\u0631\u06cc\u06ba\n- Contact your instructor for more questions\n      `,t(n),c(!0),h(!1)},500)},disabled:d||l,style:{display:"flex",alignItems:"center",gap:"0.5rem",backgroundColor:l?"#28a745":"#27ae60",color:"white",padding:"0.75rem 1.25rem",border:"none",borderRadius:"8px",fontSize:"0.95rem",fontWeight:"600",cursor:d||l?"not-allowed":"pointer",opacity:d||l?.6:1,transition:"all 0.3s"},onMouseOver:e=>{d||l||(e.target.style.transform="scale(1.05)")},onMouseOut:e=>{e.target.style.transform="scale(1)"},children:[(0,r.jsx)("span",{children:"\ud83c\uddf5\ud83c\uddf0"}),l?"\u0627\u0631\u062f\u0648 \u0645\u06cc\u06ba \u2713":"Translate to Urdu"]}),(o||l)&&(0,r.jsxs)("button",{onClick:()=>{t(e),a(!1),c(!1)},style:{display:"flex",alignItems:"center",gap:"0.5rem",backgroundColor:"#6c757d",color:"white",padding:"0.75rem 1.25rem",border:"none",borderRadius:"8px",fontSize:"0.95rem",fontWeight:"600",cursor:"pointer",transition:"all 0.3s"},onMouseOver:e=>{e.target.style.transform="scale(1.05)"},onMouseOut:e=>{e.target.style.transform="scale(1)"},children:[(0,r.jsx)("span",{children:"\u21ba"}),"Reset to Original"]})]}),(0,r.jsx)("div",{style:{backgroundColor:"white",borderRadius:"8px",padding:"1.5rem",border:"1px solid #dee2e6",minHeight:"200px"},children:d?(0,r.jsx)("div",{style:{display:"flex",alignItems:"center",justifyContent:"center",padding:"3rem"},children:(0,r.jsx)("div",{style:{width:"40px",height:"40px",border:"4px solid #f3f3f3",borderTop:"4px solid #667eea",borderRadius:"50%",animation:"spin 1s linear infinite"}})}):(0,r.jsx)("div",{style:{whiteSpace:"pre-wrap",lineHeight:"1.6",color:"#333"},children:s})}),!d&&(0,r.jsxs)("div",{style:{marginTop:"1rem",display:"flex",flexWrap:"wrap",gap:"0.5rem"},children:[o&&(0,r.jsxs)("span",{style:{backgroundColor:"#e7d4f7",color:"#6f42c1",padding:"0.4rem 0.8rem",borderRadius:"20px",fontSize:"0.85rem",fontWeight:"600"},children:["\ud83c\udfaf Tailored to ",n?.experienceLevel||"your"," level"]}),l&&(0,r.jsx)("span",{style:{backgroundColor:"#d4edda",color:"#155724",padding:"0.4rem 0.8rem",borderRadius:"20px",fontSize:"0.85rem",fontWeight:"600"},children:"\ud83c\uddf5\ud83c\uddf0 \u0627\u0631\u062f\u0648 Translation Active"})]}),(0,r.jsx)("style",{children:"\n        @keyframes spin {\n          0% { transform: rotate(0deg); }\n          100% { transform: rotate(360deg); }\n        }\n      "})]})}},8453:(e,n,s)=>{s.d(n,{R:()=>o,x:()=>a});var i=s(6540);const r={},t=i.createContext(r);function o(e){const n=i.useContext(t);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);